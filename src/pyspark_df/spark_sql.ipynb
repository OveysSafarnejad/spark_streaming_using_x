{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbec3be9-68de-46c4-bfda-2dbfb23b1ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import findspark\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType, MapType, DateType\n",
    "from pyspark.sql.functions import col, lit, explode, split , array, array_contains, \\\n",
    "    udf, map_values, when, count, min, max, avg, row_number, rank, dense_rank, percent_rank, \\\n",
    "    lead, lag, first, last, nth_value, from_json, map_keys, to_json, json_tuple\n",
    "import pyspark.sql.functions as sql_functions\n",
    "\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bfcaee4-5c07-4daa-87b9-277656eacd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/07 20:25:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Spark SQL').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7807ab0-c315-4a95-8dd7-8e7691aa1fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_df = spark.createDataFrame(\n",
    "    data=[(1,'ali'),(2, 'akram'),(3, 'oveys'),(4, 'ala'),(5, 'omid'),(6, 'mobin')], schema=['id', 'name']\n",
    ")\n",
    "\n",
    "right_df = spark.createDataFrame(\n",
    "        data=[(8,'mehdi'),(9, 'simin'),(3, 'oveys'),(4, 'ala'),(10, 'aida')], schema=['id', 'name']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50c93334-c356-466c-824e-d130930aa949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+\n",
      "| id| name| name|\n",
      "+---+-----+-----+\n",
      "|  1|  ali| NULL|\n",
      "|  2|akram| NULL|\n",
      "|  3|oveys|oveys|\n",
      "|  4|  ala|  ala|\n",
      "|  5| omid| NULL|\n",
      "|  6|mobin| NULL|\n",
      "+---+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# options are inner, outer, left, right\n",
    "left_df.join(right_df, on=['id'], how='left').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf6b2181-59b8-424b-856e-e5a952d35331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|name|\n",
      "+---+----+\n",
      "|  1|   a|\n",
      "|  2|   b|\n",
      "|  1|   d|\n",
      "|  3|   b|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True)\n",
    "])\n",
    "\n",
    "rdd1 = spark.sparkContext.parallelize([(1,'a'),(2, 'b')])\n",
    "rdd2 = spark.sparkContext.parallelize([(1,'d'),(3, 'b')])\n",
    "rdd_res = rdd1.union(rdd2)\n",
    "\n",
    "spark.createDataFrame(rdd_res, schema).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2f7b557-fc8d-4404-ba7a-7a634dc5fcb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+\n",
      "|pid|survived|class|                name|   sex| age|sib|parch|          tikcet|   fare|cabin|embarked|\n",
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+\n",
      "|  1|       0|    3|Braund, Mr. Owen ...|  male|  22|  1|    0|       A/5 21171|   7.25| NULL|       S|\n",
      "|  2|       1|    1|Cumings, Mrs. Joh...|female|  38|  1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|  3|       1|    3|Heikkinen, Miss. ...|female|  26|  0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
      "|  4|       1|    1|Futrelle, Mrs. Ja...|female|  35|  1|    0|          113803|   53.1| C123|       S|\n",
      "|  5|       0|    3|Allen, Mr. Willia...|  male|  35|  0|    0|          373450|   8.05| NULL|       S|\n",
      "|  6|       0|    3|    Moran, Mr. James|  male|NULL|  0|    0|          330877| 8.4583| NULL|       Q|\n",
      "|  7|       0|    1|McCarthy, Mr. Tim...|  male|  54|  0|    0|           17463|51.8625|  E46|       S|\n",
      "|  8|       0|    3|Palsson, Master. ...|  male|   2|  3|    1|          349909| 21.075| NULL|       S|\n",
      "|  9|       1|    3|Johnson, Mrs. Osc...|female|  27|  0|    2|          347742|11.1333| NULL|       S|\n",
      "| 10|       1|    2|Nasser, Mrs. Nich...|female|  14|  1|    0|          237736|30.0708| NULL|       C|\n",
      "| 11|       1|    3|Sandstrom, Miss. ...|female|   4|  1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "| 12|       1|    1|Bonnell, Miss. El...|female|  58|  0|    0|          113783|  26.55| C103|       S|\n",
      "| 13|       0|    3|Saundercock, Mr. ...|  male|  20|  0|    0|       A/5. 2151|   8.05| NULL|       S|\n",
      "| 14|       0|    3|Andersson, Mr. An...|  male|  39|  1|    5|          347082| 31.275| NULL|       S|\n",
      "| 15|       0|    3|Vestrom, Miss. Hu...|female|  14|  0|    0|          350406| 7.8542| NULL|       S|\n",
      "| 16|       1|    2|Hewlett, Mrs. (Ma...|female|  55|  0|    0|          248706|   16.0| NULL|       S|\n",
      "| 17|       0|    3|Rice, Master. Eugene|  male|   2|  4|    1|          382652| 29.125| NULL|       Q|\n",
      "| 18|       1|    2|Williams, Mr. Cha...|  male|NULL|  0|    0|          244373|   13.0| NULL|       S|\n",
      "| 19|       0|    3|Vander Planke, Mr...|female|  31|  1|    0|          345763|   18.0| NULL|       S|\n",
      "| 20|       1|    3|Masselmani, Mrs. ...|female|NULL|  0|    0|            2649|  7.225| NULL|       C|\n",
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/04 16:23:43 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked\n",
      " Schema: pid, survived, class, name, sex, age, sib, parch, tikcet, fare, cabin, embarked\n",
      "Expected: pid but found: PassengerId\n",
      "CSV file: file:///Users/hso/Documents/WORKSPACE/LEARNING/spark_streaming_using_x/src/pyspark_df/titanic.csv\n"
     ]
    }
   ],
   "source": [
    "titanic_shcema = StructType()\\\n",
    "    .add('pid', 'integer') \\\n",
    "    .add('survived', 'integer') \\\n",
    "    .add('class', 'integer') \\\n",
    "    .add('name', 'string') \\\n",
    "    .add('sex', 'string') \\\n",
    "    .add('age', 'integer') \\\n",
    "    .add('sib', 'integer') \\\n",
    "    .add('parch', 'integer') \\\n",
    "    .add('tikcet', 'string') \\\n",
    "    .add('fare', 'float') \\\n",
    "    .add('cabin', 'string') \\\n",
    "    .add('embarked', 'string') \\\n",
    "\n",
    "\n",
    "\n",
    "titanic_df = spark.read.option('header', 'true').schema(titanic_shcema).csv('titanic.csv')\n",
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0a70fb5-dda5-4210-b446-fe581c41b2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+\n",
      "|pid|survived|class|                name|   sex| age|sib|parch|          tikcet|   fare|cabin|embarked|\n",
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+\n",
      "|  1|       0|    3|Braund, Mr. Owen ...|  male|  22|  1|    0|       A/5 21171|   7.25| NULL|       S|\n",
      "|  2|       1|    1|Cumings, Mrs. Joh...|female|  38|  1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|  3|       1|    3|Heikkinen, Miss. ...|female|  26|  0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
      "|  4|       1|    1|Futrelle, Mrs. Ja...|female|  35|  1|    0|          113803|   53.1| C123|       S|\n",
      "|  5|       0|    3|Allen, Mr. Willia...|  male|  35|  0|    0|          373450|   8.05| NULL|       S|\n",
      "|  6|       0|    3|    Moran, Mr. James|  male|NULL|  0|    0|          330877| 8.4583| NULL|       Q|\n",
      "|  7|       0|    1|McCarthy, Mr. Tim...|  male|  54|  0|    0|           17463|51.8625|  E46|       S|\n",
      "|  8|       0|    3|Palsson, Master. ...|  male|   2|  3|    1|          349909| 21.075| NULL|       S|\n",
      "|  9|       1|    3|Johnson, Mrs. Osc...|female|  27|  0|    2|          347742|11.1333| NULL|       S|\n",
      "| 10|       1|    2|Nasser, Mrs. Nich...|female|  14|  1|    0|          237736|30.0708| NULL|       C|\n",
      "| 11|       1|    3|Sandstrom, Miss. ...|female|   4|  1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "| 12|       1|    1|Bonnell, Miss. El...|female|  58|  0|    0|          113783|  26.55| C103|       S|\n",
      "| 13|       0|    3|Saundercock, Mr. ...|  male|  20|  0|    0|       A/5. 2151|   8.05| NULL|       S|\n",
      "| 14|       0|    3|Andersson, Mr. An...|  male|  39|  1|    5|          347082| 31.275| NULL|       S|\n",
      "| 15|       0|    3|Vestrom, Miss. Hu...|female|  14|  0|    0|          350406| 7.8542| NULL|       S|\n",
      "| 16|       1|    2|Hewlett, Mrs. (Ma...|female|  55|  0|    0|          248706|   16.0| NULL|       S|\n",
      "| 17|       0|    3|Rice, Master. Eugene|  male|   2|  4|    1|          382652| 29.125| NULL|       Q|\n",
      "| 18|       1|    2|Williams, Mr. Cha...|  male|NULL|  0|    0|          244373|   13.0| NULL|       S|\n",
      "| 19|       0|    3|Vander Planke, Mr...|female|  31|  1|    0|          345763|   18.0| NULL|       S|\n",
      "| 20|       1|    3|Masselmani, Mrs. ...|female|NULL|  0|    0|            2649|  7.225| NULL|       C|\n",
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/04 16:23:43 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked\n",
      " Schema: pid, survived, class, name, sex, age, sib, parch, tikcet, fare, cabin, embarked\n",
      "Expected: pid but found: PassengerId\n",
      "CSV file: file:///Users/hso/Documents/WORKSPACE/LEARNING/spark_streaming_using_x/src/pyspark_df/titanic.csv\n"
     ]
    }
   ],
   "source": [
    "titanic_1 = titanic_df.alias('titanic_1')\n",
    "\n",
    "titanic_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73a4f74f-8e56-46d7-8f68-438d508401f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|cabin|\n",
      "+-----+\n",
      "| NULL|\n",
      "|  C85|\n",
      "| NULL|\n",
      "| C123|\n",
      "| NULL|\n",
      "| NULL|\n",
      "|  E46|\n",
      "| NULL|\n",
      "| NULL|\n",
      "| NULL|\n",
      "|   G6|\n",
      "| C103|\n",
      "| NULL|\n",
      "| NULL|\n",
      "| NULL|\n",
      "| NULL|\n",
      "| NULL|\n",
      "| NULL|\n",
      "| NULL|\n",
      "| NULL|\n",
      "+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_1.select('cabin').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfc1dede-45ff-412e-a373-3f87536a32e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_1.filter(titanic_1.age > 35).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40bbb422-042b-42e9-b1be-d3da4d46fb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+--------+\n",
      "|                name| age|survived|\n",
      "+--------------------+----+--------+\n",
      "|Braund, Mr. Owen ...|  22|       0|\n",
      "|Allen, Mr. Willia...|  35|       0|\n",
      "|    Moran, Mr. James|NULL|       0|\n",
      "|McCarthy, Mr. Tim...|  54|       0|\n",
      "|Palsson, Master. ...|   2|       0|\n",
      "|Saundercock, Mr. ...|  20|       0|\n",
      "|Andersson, Mr. An...|  39|       0|\n",
      "|Vestrom, Miss. Hu...|  14|       0|\n",
      "|Rice, Master. Eugene|   2|       0|\n",
      "|Vander Planke, Mr...|  31|       0|\n",
      "|Fynney, Mr. Joseph J|  35|       0|\n",
      "|Palsson, Miss. To...|   8|       0|\n",
      "|Emir, Mr. Farred ...|NULL|       0|\n",
      "|Fortune, Mr. Char...|  19|       0|\n",
      "| Todoroff, Mr. Lalio|NULL|       0|\n",
      "|Uruchurtu, Don. M...|  40|       0|\n",
      "|Wheadon, Mr. Edwa...|  66|       0|\n",
      "|Meyer, Mr. Edgar ...|  28|       0|\n",
      "|Holverson, Mr. Al...|  42|       0|\n",
      "|Cann, Mr. Ernest ...|  21|       0|\n",
      "+--------------------+----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_1.select('name', 'age', 'survived').filter('survived = 0').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4429e21-bf2a-4c3f-a0de-214a6197f1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|                name|survived|\n",
      "+--------------------+--------+\n",
      "|Heikkinen, Miss. ...|       1|\n",
      "|Johnson, Mrs. Osc...|       1|\n",
      "|Nasser, Mrs. Nich...|       1|\n",
      "|Sandstrom, Miss. ...|       1|\n",
      "|\"McGowan, Miss. A...|       1|\n",
      "|Sloper, Mr. Willi...|       1|\n",
      "|Nicola-Yarred, Mi...|       1|\n",
      "|Laroche, Miss. Si...|       1|\n",
      "|Devaney, Miss. Ma...|       1|\n",
      "|Faunthorpe, Mrs. ...|       1|\n",
      "|   Rugg, Miss. Emily|       1|\n",
      "|West, Miss. Const...|       1|\n",
      "|Nye, Mrs. (Elizab...|       1|\n",
      "|Andersson, Miss. ...|       1|\n",
      "|Sheerlinck, Mr. J...|       1|\n",
      "| Ilett, Miss. Bertha|       1|\n",
      "|Fortune, Miss. Ma...|       1|\n",
      "|Greenfield, Mr. W...|       1|\n",
      "|Salkjelsvik, Miss...|       1|\n",
      "|Nicola-Yarred, Ma...|       1|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_1.select('name', 'survived').where('age < 30 and survived=1').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e63c8da0-5bec-4204-b3ae-6958956688ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+--------------------+------+---+---+-----+-----------+-------+-----------+--------+\n",
      "|pid|survived|class|                name|   sex|age|sib|parch|     tikcet|   fare|      cabin|embarked|\n",
      "+---+--------+-----+--------------------+------+---+---+-----+-----------+-------+-----------+--------+\n",
      "|631|       1|    1|Barkworth, Mr. Al...|  male| 80|  0|    0|      27042|   30.0|        A23|       S|\n",
      "|852|       0|    3| Svensson, Mr. Johan|  male| 74|  0|    0|     347060|  7.775|       NULL|       S|\n",
      "|494|       0|    1|Artagaveytia, Mr....|  male| 71|  0|    0|   PC 17609|49.5042|       NULL|       C|\n",
      "| 97|       0|    1|Goldschmidt, Mr. ...|  male| 71|  0|    0|   PC 17754|34.6542|         A5|       C|\n",
      "|746|       0|    1|Crosby, Capt. Edw...|  male| 70|  1|    1|  WE/P 5735|   71.0|        B22|       S|\n",
      "|673|       0|    2|Mitchell, Mr. Hen...|  male| 70|  0|    0| C.A. 24580|   10.5|       NULL|       S|\n",
      "| 34|       0|    2|Wheadon, Mr. Edwa...|  male| 66|  0|    0| C.A. 24579|   10.5|       NULL|       S|\n",
      "|281|       0|    3|    Duane, Mr. Frank|  male| 65|  0|    0|     336439|   7.75|       NULL|       Q|\n",
      "|457|       0|    1|Millet, Mr. Franc...|  male| 65|  0|    0|      13509|  26.55|        E38|       S|\n",
      "| 55|       0|    1|Ostby, Mr. Engelh...|  male| 65|  0|    1|     113509|61.9792|        B30|       C|\n",
      "|439|       0|    1|   Fortune, Mr. Mark|  male| 64|  1|    4|      19950|  263.0|C23 C25 C27|       S|\n",
      "|546|       0|    1|Nicholson, Mr. Ar...|  male| 64|  0|    0|        693|   26.0|       NULL|       S|\n",
      "|276|       1|    1|Andrews, Miss. Ko...|female| 63|  1|    0|      13502|77.9583|         D7|       S|\n",
      "|484|       1|    3|Turkula, Mrs. (He...|female| 63|  0|    0|       4134| 9.5875|       NULL|       S|\n",
      "|571|       1|    2|  Harris, Mr. George|  male| 62|  0|    0|S.W./PP 752|   10.5|       NULL|       S|\n",
      "|253|       0|    1|Stead, Mr. Willia...|  male| 62|  0|    0|     113514|  26.55|        C87|       S|\n",
      "|830|       1|    1|Stone, Mrs. Georg...|female| 62|  0|    0|     113572|   80.0|        B28|    NULL|\n",
      "|556|       0|    1|  Wright, Mr. George|  male| 62|  0|    0|     113807|  26.55|       NULL|       S|\n",
      "|327|       0|    3|Nysveen, Mr. Joha...|  male| 61|  0|    0|     345364| 6.2375|       NULL|       S|\n",
      "|626|       0|    1|Sutton, Mr. Frede...|  male| 61|  0|    0|      36963|32.3208|        D50|       S|\n",
      "+---+--------+-----+--------------------+------+---+---+-----+-----------+-------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/04 16:23:44 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked\n",
      " Schema: pid, survived, class, name, sex, age, sib, parch, tikcet, fare, cabin, embarked\n",
      "Expected: pid but found: PassengerId\n",
      "CSV file: file:///Users/hso/Documents/WORKSPACE/LEARNING/spark_streaming_using_x/src/pyspark_df/titanic.csv\n"
     ]
    }
   ],
   "source": [
    "titanic_1.sort(['age', 'name'], ascending=[False, True]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff0714a5-adde-4a4a-8ce4-0db14cf69e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/04 16:23:45 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "24/04/04 16:23:45 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked\n",
      " Schema: pid, survived, class, name, sex, age, sib, parch, tikcet, fare, cabin, embarked\n",
      "Expected: pid but found: PassengerId\n",
      "CSV file: file:///Users/hso/Documents/WORKSPACE/LEARNING/spark_streaming_using_x/src/pyspark_df/titanic.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "|summary|              pid|           survived|             class|                name|   sex|               age|               sib|              parch|            tikcet|             fare|cabin|embarked|\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "|  count|              891|                891|               891|                 891|   891|               689|               891|                891|               891|              891|  204|     889|\n",
      "|   mean|            446.0| 0.3838383838383838| 2.308641975308642|                NULL|  NULL|29.847605224963715|0.5230078563411896|0.38159371492704824|260318.54916792738|32.20420804114722| NULL|    NULL|\n",
      "| stddev|257.3538420152301|0.48659245426485753|0.8360712409770491|                NULL|  NULL|14.317668714749662|1.1027434322934315| 0.8060572211299488|471609.26868834975|49.69342916316158| NULL|    NULL|\n",
      "|    min|                1|                  0|                 1|\"Andersson, Mr. A...|female|                 1|                 0|                  0|            110152|              0.0|  A10|       C|\n",
      "|    max|              891|                  1|                 3|van Melkebeke, Mr...|  male|                80|                 8|                  6|         WE/P 5735|         512.3292|    T|       S|\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_1.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbef9dc9-5457-4fa2-9e07-4fa2c924bf4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pid',\n",
       " 'survived',\n",
       " 'class',\n",
       " 'name',\n",
       " 'sex',\n",
       " 'age',\n",
       " 'sib',\n",
       " 'parch',\n",
       " 'tikcet',\n",
       " 'fare',\n",
       " 'cabin',\n",
       " 'embarked']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4b01f69-f585-4e7c-ac71-d45ecfedcec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pid: integer (nullable = true)\n",
      " |-- survived: integer (nullable = true)\n",
      " |-- class: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sib: integer (nullable = true)\n",
      " |-- parch: integer (nullable = true)\n",
      " |-- tikcet: string (nullable = true)\n",
      " |-- fare: float (nullable = true)\n",
      " |-- cabin: string (nullable = true)\n",
      " |-- embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e020cdf-b30b-4503-9922-b83898bc79b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method withColumn in module pyspark.sql.dataframe:\n",
      "\n",
      "withColumn(colName: str, col: pyspark.sql.column.Column) -> 'DataFrame' method of pyspark.sql.dataframe.DataFrame instance\n",
      "    Returns a new :class:`DataFrame` by adding a column or replacing the\n",
      "    existing column that has the same name.\n",
      "    \n",
      "    The column expression must be an expression over this :class:`DataFrame`; attempting to add\n",
      "    a column from some other :class:`DataFrame` will raise an error.\n",
      "    \n",
      "    .. versionadded:: 1.3.0\n",
      "    \n",
      "    .. versionchanged:: 3.4.0\n",
      "        Supports Spark Connect.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    colName : str\n",
      "        string, name of the new column.\n",
      "    col : :class:`Column`\n",
      "        a :class:`Column` expression for the new column.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    :class:`DataFrame`\n",
      "        DataFrame with new or replaced column.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    This method introduces a projection internally. Therefore, calling it multiple\n",
      "    times, for instance, via loops in order to add multiple columns can generate big\n",
      "    plans which can cause performance issues and even `StackOverflowException`.\n",
      "    To avoid this, use :func:`select` with multiple columns at once.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = spark.createDataFrame([(2, \"Alice\"), (5, \"Bob\")], schema=[\"age\", \"name\"])\n",
      "    >>> df.withColumn('age2', df.age + 2).show()\n",
      "    +---+-----+----+\n",
      "    |age| name|age2|\n",
      "    +---+-----+----+\n",
      "    |  2|Alice|   4|\n",
      "    |  5|  Bob|   7|\n",
      "    +---+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(titanic_1.withColumn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46baea75-1630-4b11-976e-65aa39ee1d3d",
   "metadata": {},
   "source": [
    "# withColumn()\n",
    "\n",
    "##### It's a transformation operation which is used for \n",
    "##### 1. adding a new column\n",
    "##### 2. changing the dtype of an existing column\n",
    "##### 3. changing the value of an existing column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a00d9a5c-6198-4226-a7e5-51c4c8a6f06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+\n",
      "|pid|survived|class|                name|   sex| age|sib|parch|          tikcet|   fare|cabin|embarked|\n",
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+\n",
      "|  1|       0|    3|Braund, Mr. Owen ...|  male|  22|1.0|    0|       A/5 21171|   7.25| NULL|       S|\n",
      "|  2|       1|    1|Cumings, Mrs. Joh...|female|  38|1.0|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|  3|       1|    3|Heikkinen, Miss. ...|female|  26|0.0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
      "|  4|       1|    1|Futrelle, Mrs. Ja...|female|  35|1.0|    0|          113803|   53.1| C123|       S|\n",
      "|  5|       0|    3|Allen, Mr. Willia...|  male|  35|0.0|    0|          373450|   8.05| NULL|       S|\n",
      "|  6|       0|    3|    Moran, Mr. James|  male|NULL|0.0|    0|          330877| 8.4583| NULL|       Q|\n",
      "|  7|       0|    1|McCarthy, Mr. Tim...|  male|  54|0.0|    0|           17463|51.8625|  E46|       S|\n",
      "|  8|       0|    3|Palsson, Master. ...|  male|   2|3.0|    1|          349909| 21.075| NULL|       S|\n",
      "|  9|       1|    3|Johnson, Mrs. Osc...|female|  27|0.0|    2|          347742|11.1333| NULL|       S|\n",
      "| 10|       1|    2|Nasser, Mrs. Nich...|female|  14|1.0|    0|          237736|30.0708| NULL|       C|\n",
      "| 11|       1|    3|Sandstrom, Miss. ...|female|   4|1.0|    1|         PP 9549|   16.7|   G6|       S|\n",
      "| 12|       1|    1|Bonnell, Miss. El...|female|  58|0.0|    0|          113783|  26.55| C103|       S|\n",
      "| 13|       0|    3|Saundercock, Mr. ...|  male|  20|0.0|    0|       A/5. 2151|   8.05| NULL|       S|\n",
      "| 14|       0|    3|Andersson, Mr. An...|  male|  39|1.0|    5|          347082| 31.275| NULL|       S|\n",
      "| 15|       0|    3|Vestrom, Miss. Hu...|female|  14|0.0|    0|          350406| 7.8542| NULL|       S|\n",
      "| 16|       1|    2|Hewlett, Mrs. (Ma...|female|  55|0.0|    0|          248706|   16.0| NULL|       S|\n",
      "| 17|       0|    3|Rice, Master. Eugene|  male|   2|4.0|    1|          382652| 29.125| NULL|       Q|\n",
      "| 18|       1|    2|Williams, Mr. Cha...|  male|NULL|0.0|    0|          244373|   13.0| NULL|       S|\n",
      "| 19|       0|    3|Vander Planke, Mr...|female|  31|1.0|    0|          345763|   18.0| NULL|       S|\n",
      "| 20|       1|    3|Masselmani, Mrs. ...|female|NULL|0.0|    0|            2649|  7.225| NULL|       C|\n",
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/04 16:23:46 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked\n",
      " Schema: pid, survived, class, name, sex, age, sib, parch, tikcet, fare, cabin, embarked\n",
      "Expected: pid but found: PassengerId\n",
      "CSV file: file:///Users/hso/Documents/WORKSPACE/LEARNING/spark_streaming_using_x/src/pyspark_df/titanic.csv\n"
     ]
    }
   ],
   "source": [
    "# change dtype\n",
    "titanic_1.withColumn(colName='sib', col=titanic_1.sib.cast('float')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcc70812-1344-4ee8-ac04-6abdb019c43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+\n",
      "|pid|survived|class|                name|   sex| age|sib|parch|          tikcet|   fare|cabin|embarked|\n",
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+\n",
      "|  1|       0|    3|Braund, Mr. Owen ...|  male|  22|  1|    0|       A/5 21171|   7.25| NULL|       S|\n",
      "|  2|       1|    1|Cumings, Mrs. Joh...|female|  38|  1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|  3|       1|    3|Heikkinen, Miss. ...|female|  26|  0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
      "|  4|       1|    1|Futrelle, Mrs. Ja...|female|  35|  1|    0|          113803|   53.1| C123|       S|\n",
      "|  5|       0|    3|Allen, Mr. Willia...|  male|  35|  0|    0|          373450|   8.05| NULL|       S|\n",
      "|  6|       0|    3|    Moran, Mr. James|  male|NULL|  0|    0|          330877| 8.4583| NULL|       Q|\n",
      "|  7|       0|    1|McCarthy, Mr. Tim...|  male|  54|  0|    0|           17463|51.8625|  E46|       S|\n",
      "|  8|       0|    3|Palsson, Master. ...|  male|   2|  3|    1|          349909| 21.075| NULL|       S|\n",
      "|  9|       1|    3|Johnson, Mrs. Osc...|female|  27|  0|    2|          347742|11.1333| NULL|       S|\n",
      "| 10|       1|    2|Nasser, Mrs. Nich...|female|  14|  1|    0|          237736|30.0708| NULL|       C|\n",
      "| 11|       1|    3|Sandstrom, Miss. ...|female|   4|  1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "| 12|       1|    1|Bonnell, Miss. El...|female|  58|  0|    0|          113783|  26.55| C103|       S|\n",
      "| 13|       0|    3|Saundercock, Mr. ...|  male|  20|  0|    0|       A/5. 2151|   8.05| NULL|       S|\n",
      "| 14|       0|    3|Andersson, Mr. An...|  male|  39|  1|    5|          347082| 31.275| NULL|       S|\n",
      "| 15|       0|    3|Vestrom, Miss. Hu...|female|  14|  0|    0|          350406| 7.8542| NULL|       S|\n",
      "| 16|       1|    2|Hewlett, Mrs. (Ma...|female|  55|  0|    0|          248706|   16.0| NULL|       S|\n",
      "| 17|       0|    3|Rice, Master. Eugene|  male|   2|  4|    1|          382652| 29.125| NULL|       Q|\n",
      "| 18|       1|    2|Williams, Mr. Cha...|  male|NULL|  0|    0|          244373|   13.0| NULL|       S|\n",
      "| 19|       0|    3|Vander Planke, Mr...|female|  31|  1|    0|          345763|   18.0| NULL|       S|\n",
      "| 20|       1|    3|Masselmani, Mrs. ...|female|NULL|  0|    0|            2649|  7.225| NULL|       C|\n",
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/04 16:23:46 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked\n",
      " Schema: pid, survived, class, name, sex, age, sib, parch, tikcet, fare, cabin, embarked\n",
      "Expected: pid but found: PassengerId\n",
      "CSV file: file:///Users/hso/Documents/WORKSPACE/LEARNING/spark_streaming_using_x/src/pyspark_df/titanic.csv\n"
     ]
    }
   ],
   "source": [
    "# data manipulation\n",
    "titanic_1.withColumn('sib', titanic_1.sib * 1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5eb6f0a9-2e3f-430c-96c6-2f565409663f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+-----------+\n",
      "|pid|survived|class|                name|   sex| age|sib|parch|          tikcet|   fare|cabin|embarked|nationality|\n",
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+-----------+\n",
      "|  1|       0|    3|Braund, Mr. Owen ...|  male|  22|  1|    0|       A/5 21171|   7.25| NULL|       S|        XYZ|\n",
      "|  2|       1|    1|Cumings, Mrs. Joh...|female|  38|  1|    0|        PC 17599|71.2833|  C85|       C|        XYZ|\n",
      "|  3|       1|    3|Heikkinen, Miss. ...|female|  26|  0|    0|STON/O2. 3101282|  7.925| NULL|       S|        XYZ|\n",
      "|  4|       1|    1|Futrelle, Mrs. Ja...|female|  35|  1|    0|          113803|   53.1| C123|       S|        XYZ|\n",
      "|  5|       0|    3|Allen, Mr. Willia...|  male|  35|  0|    0|          373450|   8.05| NULL|       S|        XYZ|\n",
      "|  6|       0|    3|    Moran, Mr. James|  male|NULL|  0|    0|          330877| 8.4583| NULL|       Q|        XYZ|\n",
      "|  7|       0|    1|McCarthy, Mr. Tim...|  male|  54|  0|    0|           17463|51.8625|  E46|       S|        XYZ|\n",
      "|  8|       0|    3|Palsson, Master. ...|  male|   2|  3|    1|          349909| 21.075| NULL|       S|        XYZ|\n",
      "|  9|       1|    3|Johnson, Mrs. Osc...|female|  27|  0|    2|          347742|11.1333| NULL|       S|        XYZ|\n",
      "| 10|       1|    2|Nasser, Mrs. Nich...|female|  14|  1|    0|          237736|30.0708| NULL|       C|        XYZ|\n",
      "| 11|       1|    3|Sandstrom, Miss. ...|female|   4|  1|    1|         PP 9549|   16.7|   G6|       S|        XYZ|\n",
      "| 12|       1|    1|Bonnell, Miss. El...|female|  58|  0|    0|          113783|  26.55| C103|       S|        XYZ|\n",
      "| 13|       0|    3|Saundercock, Mr. ...|  male|  20|  0|    0|       A/5. 2151|   8.05| NULL|       S|        XYZ|\n",
      "| 14|       0|    3|Andersson, Mr. An...|  male|  39|  1|    5|          347082| 31.275| NULL|       S|        XYZ|\n",
      "| 15|       0|    3|Vestrom, Miss. Hu...|female|  14|  0|    0|          350406| 7.8542| NULL|       S|        XYZ|\n",
      "| 16|       1|    2|Hewlett, Mrs. (Ma...|female|  55|  0|    0|          248706|   16.0| NULL|       S|        XYZ|\n",
      "| 17|       0|    3|Rice, Master. Eugene|  male|   2|  4|    1|          382652| 29.125| NULL|       Q|        XYZ|\n",
      "| 18|       1|    2|Williams, Mr. Cha...|  male|NULL|  0|    0|          244373|   13.0| NULL|       S|        XYZ|\n",
      "| 19|       0|    3|Vander Planke, Mr...|female|  31|  1|    0|          345763|   18.0| NULL|       S|        XYZ|\n",
      "| 20|       1|    3|Masselmani, Mrs. ...|female|NULL|  0|    0|            2649|  7.225| NULL|       C|        XYZ|\n",
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/04 16:23:46 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked\n",
      " Schema: pid, survived, class, name, sex, age, sib, parch, tikcet, fare, cabin, embarked\n",
      "Expected: pid but found: PassengerId\n",
      "CSV file: file:///Users/hso/Documents/WORKSPACE/LEARNING/spark_streaming_using_x/src/pyspark_df/titanic.csv\n"
     ]
    }
   ],
   "source": [
    "# creating new col\n",
    "titanic_1.withColumn(colName='nationality', col=lit('XYZ')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf79114-2f85-4211-8c50-68120c01b85e",
   "metadata": {},
   "source": [
    "# withColumnRename()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c86e28c-6a4e-4fff-a0cb-2b448920dd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+\n",
      "|pid|survived|class|                name|   sex| age|sib|parch|             pnr|   fare|cabin|embarked|\n",
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+\n",
      "|  1|       0|    3|Braund, Mr. Owen ...|  male|  22|  1|    0|       A/5 21171|   7.25| NULL|       S|\n",
      "|  2|       1|    1|Cumings, Mrs. Joh...|female|  38|  1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|  3|       1|    3|Heikkinen, Miss. ...|female|  26|  0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
      "|  4|       1|    1|Futrelle, Mrs. Ja...|female|  35|  1|    0|          113803|   53.1| C123|       S|\n",
      "|  5|       0|    3|Allen, Mr. Willia...|  male|  35|  0|    0|          373450|   8.05| NULL|       S|\n",
      "|  6|       0|    3|    Moran, Mr. James|  male|NULL|  0|    0|          330877| 8.4583| NULL|       Q|\n",
      "|  7|       0|    1|McCarthy, Mr. Tim...|  male|  54|  0|    0|           17463|51.8625|  E46|       S|\n",
      "|  8|       0|    3|Palsson, Master. ...|  male|   2|  3|    1|          349909| 21.075| NULL|       S|\n",
      "|  9|       1|    3|Johnson, Mrs. Osc...|female|  27|  0|    2|          347742|11.1333| NULL|       S|\n",
      "| 10|       1|    2|Nasser, Mrs. Nich...|female|  14|  1|    0|          237736|30.0708| NULL|       C|\n",
      "| 11|       1|    3|Sandstrom, Miss. ...|female|   4|  1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "| 12|       1|    1|Bonnell, Miss. El...|female|  58|  0|    0|          113783|  26.55| C103|       S|\n",
      "| 13|       0|    3|Saundercock, Mr. ...|  male|  20|  0|    0|       A/5. 2151|   8.05| NULL|       S|\n",
      "| 14|       0|    3|Andersson, Mr. An...|  male|  39|  1|    5|          347082| 31.275| NULL|       S|\n",
      "| 15|       0|    3|Vestrom, Miss. Hu...|female|  14|  0|    0|          350406| 7.8542| NULL|       S|\n",
      "| 16|       1|    2|Hewlett, Mrs. (Ma...|female|  55|  0|    0|          248706|   16.0| NULL|       S|\n",
      "| 17|       0|    3|Rice, Master. Eugene|  male|   2|  4|    1|          382652| 29.125| NULL|       Q|\n",
      "| 18|       1|    2|Williams, Mr. Cha...|  male|NULL|  0|    0|          244373|   13.0| NULL|       S|\n",
      "| 19|       0|    3|Vander Planke, Mr...|female|  31|  1|    0|          345763|   18.0| NULL|       S|\n",
      "| 20|       1|    3|Masselmani, Mrs. ...|female|NULL|  0|    0|            2649|  7.225| NULL|       C|\n",
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/04 16:23:46 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked\n",
      " Schema: pid, survived, class, name, sex, age, sib, parch, tikcet, fare, cabin, embarked\n",
      "Expected: pid but found: PassengerId\n",
      "CSV file: file:///Users/hso/Documents/WORKSPACE/LEARNING/spark_streaming_using_x/src/pyspark_df/titanic.csv\n"
     ]
    }
   ],
   "source": [
    "titanic_1.withColumnRenamed(existing='tikcet', new='pnr').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1d161e-4da2-44be-b18d-e899bd11eaa8",
   "metadata": {},
   "source": [
    "# explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3014e335-e408-428f-81a5-c76d58cc91da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------------+\n",
      "| id|    name|              skills|\n",
      "+---+--------+--------------------+\n",
      "|  1|   Oveys|      [java, python]|\n",
      "|  2|Mohammad|[Java, Python, Do...|\n",
      "|  3|     Ala|[ObjectiveC, Swif...|\n",
      "+---+--------+--------------------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- skills: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Oveys', ['java', 'python']), (2, 'Mohammad', ['Java', 'Python', 'Docker']), (3, 'Ala',['ObjectiveC', 'Swift', 'swiftUI', 'iOS'])]\n",
    "devs = spark.createDataFrame(data, ['id', 'name', 'skills'])\n",
    "devs.show()\n",
    "devs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b509f2b0-d66f-4b54-acfb-99ddd6a181a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+\n",
      "| id|    name|    skills|\n",
      "+---+--------+----------+\n",
      "|  1|   Oveys|      java|\n",
      "|  1|   Oveys|    python|\n",
      "|  2|Mohammad|      Java|\n",
      "|  2|Mohammad|    Python|\n",
      "|  2|Mohammad|    Docker|\n",
      "|  3|     Ala|ObjectiveC|\n",
      "|  3|     Ala|     Swift|\n",
      "|  3|     Ala|   swiftUI|\n",
      "|  3|     Ala|       iOS|\n",
      "+---+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.withColumn('skills', explode(devs.skills)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5732e75d-be79-47f4-b93b-bd371949213c",
   "metadata": {},
   "source": [
    "# split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18414885-fcb2-4e9b-9854-daac06c0754a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------------+\n",
      "| id|    name|              skills|\n",
      "+---+--------+--------------------+\n",
      "|  1|   Oveys|         java,python|\n",
      "|  2|Mohammad|  Java,Python,Docker|\n",
      "|  3|     Ala|ObjectiveC,Swift,...|\n",
      "+---+--------+--------------------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- skills: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Oveys', 'java,python'), (2, 'Mohammad', 'Java,Python,Docker'), (3, 'Ala','ObjectiveC,Swift,swiftUI,iOS')]\n",
    "devs = spark.createDataFrame(data, ['id', 'name', 'skills'])\n",
    "devs.show()\n",
    "devs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e53f775-0413-4dfd-a514-6a8a3e472a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------------+\n",
      "| id|    name|              skills|\n",
      "+---+--------+--------------------+\n",
      "|  1|   Oveys|      [java, python]|\n",
      "|  2|Mohammad|[Java, Python, Do...|\n",
      "|  3|     Ala|[ObjectiveC, Swif...|\n",
      "+---+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.withColumn('skills', split('skills', ',')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79b5ec8-eec7-4097-b294-55e7dc9c2f53",
   "metadata": {},
   "source": [
    "# array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab71cf00-f29e-4ecf-aac8-4c453a020a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+-------+\n",
      "| id|    name|   skill_1|skill_2|\n",
      "+---+--------+----------+-------+\n",
      "|  1|   Oveys|      java| python|\n",
      "|  2|Mohammad|      Java| Docker|\n",
      "|  3|     Ala|ObjectiveC|  Swift|\n",
      "+---+--------+----------+-------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- skill_1: string (nullable = true)\n",
      " |-- skill_2: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Oveys', 'java','python'), (2, 'Mohammad', 'Java','Docker'), (3, 'Ala','ObjectiveC','Swift')]\n",
    "devs = spark.createDataFrame(data, ['id', 'name', 'skill_1', 'skill_2'])\n",
    "devs.show()\n",
    "devs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b720e738-ff47-4719-9ceb-f4328e6821e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+-------+-------------------+\n",
      "| id|    name|   skill_1|skill_2|             skills|\n",
      "+---+--------+----------+-------+-------------------+\n",
      "|  1|   Oveys|      java| python|     [java, python]|\n",
      "|  2|Mohammad|      Java| Docker|     [Java, Docker]|\n",
      "|  3|     Ala|ObjectiveC|  Swift|[ObjectiveC, Swift]|\n",
      "+---+--------+----------+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.withColumn('skills', array('skill_1', 'skill_2')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e403bd5-9fc9-49ef-8739-169d684cf962",
   "metadata": {},
   "source": [
    "# array_contains()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1cf9b5dc-5bc8-4872-bd05-5838ff1e465a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------------+\n",
      "| id|    name|              skills|\n",
      "+---+--------+--------------------+\n",
      "|  1|   Oveys|      [java, python]|\n",
      "|  2|Mohammad|[Java, Python, Do...|\n",
      "|  3|     Ala|[ObjectiveC, Swif...|\n",
      "+---+--------+--------------------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- skills: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Oveys', ['java', 'python']), (2, 'Mohammad', ['Java', 'Python', 'Docker']), (3, 'Ala',['ObjectiveC', 'Swift', 'swiftUI', 'iOS'])]\n",
    "devs = spark.createDataFrame(data, ['id', 'name', 'skills'])\n",
    "devs.show()\n",
    "devs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48a43ee3-94d2-4500-ab8d-507a26b51830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------------+---------+\n",
      "| id|    name|              skills|pythonist|\n",
      "+---+--------+--------------------+---------+\n",
      "|  1|   Oveys|      [java, python]|     true|\n",
      "|  2|Mohammad|[java, python, do...|     true|\n",
      "|  3|     Ala|[objectivec, swif...|    false|\n",
      "+---+--------+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def lower_skills(skills):\n",
    "    return [skill.lower() for skill in skills]\n",
    "\n",
    "\n",
    "lower_skills_udf = udf(lower_skills, ArrayType(StringType()))\n",
    "\n",
    "devs.withColumn('skills', lower_skills_udf('skills')).withColumn('pythonist', array_contains('skills', 'python')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a33282-1aae-4c1c-b9d1-e227dbec95ee",
   "metadata": {},
   "source": [
    "# MapType() and explode() on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19192363-5a4c-4b4c-bb89-fbfb620efdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------------------+\n",
      "|id |name    |properties                |\n",
      "+---+--------+--------------------------+\n",
      "|1  |Oveys   |{age -> 31, height -> 175}|\n",
      "|2  |Mohammad|{age -> 32, height -> 165}|\n",
      "+---+--------+--------------------------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: long (valueContainsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Oveys', {'age':31, 'height':175}), (2, 'Mohammad', {'age':32, 'height':165})]\n",
    "devs = spark.createDataFrame(data, ['id', 'name', 'properties'])\n",
    "devs.show(truncate=False)\n",
    "devs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5216dc5-db3d-48d9-bd21-dcbd26b114e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------------------+------+-----+\n",
      "|id |name    |properties                |key   |value|\n",
      "+---+--------+--------------------------+------+-----+\n",
      "|1  |Oveys   |{age -> 31, height -> 175}|age   |31   |\n",
      "|1  |Oveys   |{age -> 31, height -> 175}|height|175  |\n",
      "|2  |Mohammad|{age -> 32, height -> 165}|age   |32   |\n",
      "|2  |Mohammad|{age -> 32, height -> 165}|height|165  |\n",
      "+---+--------+--------------------------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.select('id', 'name', 'properties', explode('properties')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09aa7ca3-b288-4ece-a6c0-09812dc16845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------------------+---------+\n",
      "|id |name    |properties                |values   |\n",
      "+---+--------+--------------------------+---------+\n",
      "|1  |Oveys   |{age -> 31, height -> 175}|[31, 175]|\n",
      "|2  |Mohammad|{age -> 32, height -> 165}|[32, 165]|\n",
      "+---+--------+--------------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.withColumn('values', map_values('properties')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1239e2e-8553-425a-b6ee-c5ae5104a944",
   "metadata": {},
   "source": [
    "# when() otherwise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afbf5c67-34f8-4976-b368-19ad3aa8629d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+\n",
      "| id|    name|gender|\n",
      "+---+--------+------+\n",
      "|  1|   Oveys|     m|\n",
      "|  2|Mohammad|     m|\n",
      "|  3|     Ala|     f|\n",
      "+---+--------+------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Oveys', 'm'), (2, 'Mohammad', 'm'), (3, 'Ala','f')]\n",
    "devs = spark.createDataFrame(data, ['id', 'name', 'gender'])\n",
    "devs.show()\n",
    "devs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17b60f6f-ad1b-4422-b926-6381c66b41a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+\n",
      "| id|    name|  sex|\n",
      "+---+--------+-----+\n",
      "|  1|   Oveys| true|\n",
      "|  2|Mohammad| true|\n",
      "|  3|     Ala|false|\n",
      "+---+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.select(\n",
    "    'id',\n",
    "    'name',\n",
    "    when(devs.gender=='m', value=True) \\\n",
    "    .when(devs.gender=='f', value=False) \\\n",
    "    .otherwise(value=None).alias('sex')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6c2a09b-14c4-4d9d-9bb3-238e91c8fe7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+\n",
      "| id|    name|gender|\n",
      "+---+--------+------+\n",
      "|  1|   Oveys|  true|\n",
      "|  2|Mohammad|  true|\n",
      "|  3|     Ala| false|\n",
      "+---+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.withColumn(\n",
    "    'gender',\n",
    "    when(devs.gender=='m', value=True) \\\n",
    "    .when(devs.gender=='f', value=False) \\\n",
    "    .otherwise(value=None).alias('sex')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc2393d-ac15-476a-b6cd-59398ce7d263",
   "metadata": {},
   "source": [
    "# column's functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1543b6d6-7c49-4f0e-9254-b1b5646653af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+\n",
      "| id|    name|salary|\n",
      "+---+--------+------+\n",
      "|  1|   Oveys|  4000|\n",
      "|  2|Mohammad|  5000|\n",
      "|  3|     Ala|  5500|\n",
      "+---+--------+------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Oveys', 4000), (2, 'Mohammad', 5000), (3, 'Ala',5500)]\n",
    "devs = spark.createDataFrame(data, ['id', 'name', 'salary'])\n",
    "devs.show()\n",
    "devs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e231e8a-8bec-4993-b5a2-caf204d522ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+\n",
      "|emp_id|    name|salary|\n",
      "+------+--------+------+\n",
      "|     1|   Oveys|  4000|\n",
      "|     2|Mohammad|  5000|\n",
      "|     3|     Ala|  5500|\n",
      "+------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# alias()\n",
    "devs.select(devs.id.alias('emp_id'), devs.name, devs.salary).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "866353d2-782d-47f3-b9d2-16b56063435f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+\n",
      "| id|    name|salary|\n",
      "+---+--------+------+\n",
      "|  1|   Oveys|  4000|\n",
      "|  2|Mohammad|  5000|\n",
      "|  3|     Ala|  5500|\n",
      "+---+--------+------+\n",
      "\n",
      "+---+--------+------+\n",
      "| id|    name|salary|\n",
      "+---+--------+------+\n",
      "|  3|     Ala|  5500|\n",
      "|  2|Mohammad|  5000|\n",
      "|  1|   Oveys|  4000|\n",
      "+---+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# asc() and desc()\n",
    "devs.sort(devs.salary.asc()).show()\n",
    "devs.sort(devs.salary.desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d32fe980-ed3f-46ff-8ffb-73c51181c077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+\n",
      "| id|    name|salary|\n",
      "+---+--------+------+\n",
      "|  1|   Oveys|4000.0|\n",
      "|  2|Mohammad|5000.0|\n",
      "|  3|     Ala|5500.0|\n",
      "+---+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cast()\n",
    "devs.select('id', 'name', devs.salary.cast('float')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0396e777-755b-47b2-8a63-d118f97e3903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+\n",
      "| id|name|salary|\n",
      "+---+----+------+\n",
      "|  3| Ala|  5500|\n",
      "+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# like()\n",
    "devs.filter(devs.name.like('A%')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558c115c-462c-4ece-9a84-e1481b799d51",
   "metadata": {},
   "source": [
    "# filter() and where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc71be13-6e75-40ea-966a-987e89208014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+\n",
      "| id|    name|salary|\n",
      "+---+--------+------+\n",
      "|  1|   Oveys|  4000|\n",
      "|  2|Mohammad|  5000|\n",
      "|  3|     Ala|  5500|\n",
      "+---+--------+------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Oveys', 4000), (2, 'Mohammad', 5000), (3, 'Ala',5500)]\n",
    "devs = spark.createDataFrame(data, ['id', 'name', 'salary'])\n",
    "devs.show()\n",
    "devs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d04ce94d-25f6-4b3b-bda9-5d279921e3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+\n",
      "| id| name|salary|\n",
      "+---+-----+------+\n",
      "|  1|Oveys|  4000|\n",
      "+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.filter('salary == 4000').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4240a30a-daf7-45dd-bdfd-0a4f17250774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+\n",
      "| id| name|salary|\n",
      "+---+-----+------+\n",
      "|  1|Oveys|  4000|\n",
      "+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.filter(devs.salary == 4000).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3fd33ff1-dcdb-44e9-894d-695c2f0b3bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+\n",
      "| id|name|salary|\n",
      "+---+----+------+\n",
      "|  3| Ala|  5500|\n",
      "+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.where((devs.salary >= 5000) & (devs.name.like('A%'))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1787cd7-2b69-40b1-85db-94a1d0989e04",
   "metadata": {},
   "source": [
    "# distinct() & drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7b969faf-bc78-472a-bf1f-f3aa16ddab2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+------+\n",
      "| id|    name|gender|salary|\n",
      "+---+--------+------+------+\n",
      "|  1|   Oveys|     M|  4000|\n",
      "|  2|Mohammad|     M|  5000|\n",
      "|  2|Mohammad|     M|  5000|\n",
      "|  3|     Ala|     F|  5500|\n",
      "+---+--------+------+------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Oveys','M', 4000), (2, 'Mohammad', 'M', 5000), (2, 'Mohammad', 'M', 5000), (3, 'Ala', 'F', 5500)]\n",
    "devs = spark.createDataFrame(data, ['id', 'name', 'gender', 'salary'])\n",
    "devs.show()\n",
    "devs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "85948554-c35f-4ce8-8952-388da5d0e042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+------+\n",
      "| id|    name|gender|salary|\n",
      "+---+--------+------+------+\n",
      "|  1|   Oveys|     M|  4000|\n",
      "|  2|Mohammad|     M|  5000|\n",
      "|  3|     Ala|     F|  5500|\n",
      "+---+--------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "94833924-3f75-41d0-b7f0-9c1fa9a4fd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+------+\n",
      "| id|    name|gender|salary|\n",
      "+---+--------+------+------+\n",
      "|  1|   Oveys|     M|  4000|\n",
      "|  2|Mohammad|     M|  5000|\n",
      "|  3|     Ala|     F|  5500|\n",
      "+---+--------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drops if there is a duplicate in rows\n",
    "\n",
    "devs.drop_duplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f057b1a-6d8e-482b-9c10-d73c3e6e748a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+------+\n",
      "| id| name|gender|salary|\n",
      "+---+-----+------+------+\n",
      "|  3|  Ala|     F|  5500|\n",
      "|  1|Oveys|     M|  4000|\n",
      "+---+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drops if there is a duplicate in gender column\n",
    "\n",
    "devs.drop_duplicates(subset=['gender']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597f9b28-e736-4ca7-980c-6521c4df180a",
   "metadata": {},
   "source": [
    "# union()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "14dc7a52-a64d-4489-83e5-8799e22f240d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+------+\n",
      "| id|    name|gender|salary|\n",
      "+---+--------+------+------+\n",
      "|  1|   Oveys|     M|  4000|\n",
      "|  2|Mohammad|     M|  5000|\n",
      "|  2|Mohammad|     M|  5000|\n",
      "|  3|     Ala|     F|  5500|\n",
      "+---+--------+------+------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Oveys','M', 4000), (2, 'Mohammad', 'M', 5000), (2, 'Mohammad', 'M', 5000), (3, 'Ala', 'F', 5500)]\n",
    "devs1 = spark.createDataFrame(data, ['id', 'name', 'gender', 'salary'])\n",
    "devs.show()\n",
    "devs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "30b40f02-d4cc-436e-9c24-6ae387557bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+------+\n",
      "| id|    name|gender|salary|\n",
      "+---+--------+------+------+\n",
      "|  1|     Ali|     M|  4000|\n",
      "|  2|   Jafar|     M|  5000|\n",
      "|  2|Mohammad|     M|  5000|\n",
      "|  2|    Abas|     M|  5000|\n",
      "|  3|    Mona|     F|  5500|\n",
      "+---+--------+------+------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Ali','M', 4000), (2, 'Jafar', 'M', 5000), (2, 'Mohammad', 'M', 5000), (2, 'Abas', 'M', 5000), (3, 'Mona', 'F', 5500)]\n",
    "devs2 = spark.createDataFrame(data, ['id', 'name', 'gender', 'salary'])\n",
    "devs2.show()\n",
    "devs2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f3eaf8e3-701a-498f-9b33-71fb3f683546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 111:============================>                           (8 + 8) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+------+\n",
      "| id|    name|gender|salary|\n",
      "+---+--------+------+------+\n",
      "|  1|   Oveys|     M|  4000|\n",
      "|  2|Mohammad|     M|  5000|\n",
      "|  3|     Ala|     F|  5500|\n",
      "|  1|     Ali|     M|  4000|\n",
      "|  2|   Jafar|     M|  5000|\n",
      "|  2|    Abas|     M|  5000|\n",
      "|  3|    Mona|     F|  5500|\n",
      "+---+--------+------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "devs1.union(devs2).distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33886ae5-288b-46f8-bb92-a9792aa2fef6",
   "metadata": {},
   "source": [
    "# groupBy() and agg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "79141c7c-e01c-4f4e-9bfb-596f7e27bf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+------+\n",
      "| id|    name|gender|salary|\n",
      "+---+--------+------+------+\n",
      "|  1|     Ali|     M|  4000|\n",
      "|  2|   Jafar|     M|  5000|\n",
      "|  7|Mohammad|     M|  5700|\n",
      "|  2|    Abas|     M|  6500|\n",
      "|  3|    Mona|     F|  6200|\n",
      "+---+--------+------+------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    (1, 'Ali','M', 4000),\n",
    "    (2, 'Jafar', 'M', 5000),\n",
    "    (7, 'Mohammad', 'M', 5700),\n",
    "    (2, 'Abas', 'M', 6500),\n",
    "    (3, 'Mona', 'F', 6200)]\n",
    "devs = spark.createDataFrame(data, ['id', 'name', 'gender', 'salary'])\n",
    "devs.show()\n",
    "devs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1f62ba34-3bac-4912-840d-4e8a82c977d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+----------+----------+----------+\n",
      "|gender|emp_count|min_salary|max_salary|avg_salary|\n",
      "+------+---------+----------+----------+----------+\n",
      "|     M|        4|      4000|      6500|    5300.0|\n",
      "|     F|        1|      6200|      6200|    6200.0|\n",
      "+------+---------+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.groupby(devs.gender).agg(\n",
    "    count('*').alias('emp_count'),\n",
    "    min('salary').alias('min_salary'),\n",
    "    max('salary').alias('max_salary'),\n",
    "    avg('salary').alias('avg_salary')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d6ecf3-74a4-481c-b813-740c7a7f6341",
   "metadata": {},
   "source": [
    "# unionByName()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "869354c7-b25a-4089-9aef-62ef00c2013f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+\n",
      "| id|    name|age|salary|\n",
      "+---+--------+---+------+\n",
      "|  1|     Ali| 20|  4000|\n",
      "|  2|   Jafar| 21|  5000|\n",
      "|  2|Mohammad| 23|  5000|\n",
      "|  2|    Abas| 45|  5000|\n",
      "|  3|    Mona| 19|  5500|\n",
      "+---+--------+---+------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+---+--------+------+------+\n",
      "| id|    name|gender|salary|\n",
      "+---+--------+------+------+\n",
      "|  1|     Ali|     M|  4000|\n",
      "|  2|   Jafar|     M|  5000|\n",
      "|  2|Mohammad|     M|  5000|\n",
      "|  2|    Abas|     M|  5000|\n",
      "|  3|    Mona|     F|  5500|\n",
      "+---+--------+------+------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Ali',20, 4000), (2, 'Jafar', 21, 5000), (2, 'Mohammad', 23, 5000), (2, 'Abas', 45, 5000), (3, 'Mona', 19, 5500)]\n",
    "devs1 = spark.createDataFrame(data, ['id', 'name', 'age', 'salary'])\n",
    "devs1.show()\n",
    "devs1.printSchema()\n",
    "\n",
    "data = [(1, 'Ali','M', 4000), (2, 'Jafar', 'M', 5000), (2, 'Mohammad', 'M', 5000), (2, 'Abas', 'M', 5000), (3, 'Mona', 'F', 5500)]\n",
    "devs2 = spark.createDataFrame(data, ['id', 'name', 'gender', 'salary'])\n",
    "devs2.show()\n",
    "devs2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7cda5031-baee-4304-bd00-39b549e853ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----+------+------+\n",
      "| id|    name| age|salary|gender|\n",
      "+---+--------+----+------+------+\n",
      "|  1|     Ali|  20|  4000|  NULL|\n",
      "|  2|   Jafar|  21|  5000|  NULL|\n",
      "|  2|Mohammad|  23|  5000|  NULL|\n",
      "|  2|    Abas|  45|  5000|  NULL|\n",
      "|  3|    Mona|  19|  5500|  NULL|\n",
      "|  1|     Ali|NULL|  4000|     M|\n",
      "|  2|   Jafar|NULL|  5000|     M|\n",
      "|  2|Mohammad|NULL|  5000|     M|\n",
      "|  2|    Abas|NULL|  5000|     M|\n",
      "|  3|    Mona|NULL|  5500|     F|\n",
      "+---+--------+----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs1.unionByName(devs2, allowMissingColumns=True).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30e48fa-1a1d-4bc1-ab97-5cd59ae0efd7",
   "metadata": {},
   "source": [
    "# self join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ed1d2769-c191-44ac-ae30-9f2b20829803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+\n",
      "| id|    name|manager|\n",
      "+---+--------+-------+\n",
      "|  1|     Ali|      0|\n",
      "|  2|   Jafar|      1|\n",
      "|  3|Mohammad|      1|\n",
      "|  4|    Abas|      3|\n",
      "|  5|    Mona|      2|\n",
      "+---+--------+-------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- manager: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Ali',0), (2, 'Jafar', 1), (3, 'Mohammad', 1), (4, 'Abas', 3), (5, 'Mona', 2)]\n",
    "devs = spark.createDataFrame(data, ['id', 'name', 'manager'])\n",
    "devs.show()\n",
    "devs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "19e564ac-ea60-432b-a108-165d5b2e286a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+----+--------+-------+\n",
      "| id|    name|manager|  id|    name|manager|\n",
      "+---+--------+-------+----+--------+-------+\n",
      "|  1|     Ali|      0|NULL|    NULL|   NULL|\n",
      "|  2|   Jafar|      1|   1|     Ali|      0|\n",
      "|  3|Mohammad|      1|   1|     Ali|      0|\n",
      "|  4|    Abas|      3|   3|Mohammad|      1|\n",
      "|  5|    Mona|      2|   2|   Jafar|      1|\n",
      "+---+--------+-------+----+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.alias('emp').join(\n",
    "    devs.alias('mngr'),\n",
    "    col('emp.manager') == col('mngr.id'),\n",
    "    how='left'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86e3431-3ba7-4653-bcb8-fd6afb88807d",
   "metadata": {},
   "source": [
    "# pivot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "77dfc180-f388-43e5-be55-a5c5a37f55d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+----------+\n",
      "| id|    name|gender|department|\n",
      "+---+--------+------+----------+\n",
      "|  1|     Ali|     M|        IT|\n",
      "|  2|   Jafar|     F|        HR|\n",
      "|  3|Mohammad|     M|        HR|\n",
      "|  4|    Abas|     F|        IT|\n",
      "|  5|    Mona|     T|       FIN|\n",
      "+---+--------+------+----------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Ali','M', 'IT'), (2, 'Jafar', 'F', 'HR'), (3, 'Mohammad', 'M', 'HR'), (4, 'Abas', 'F', 'IT'), (5, 'Mona', 'T', 'FIN')]\n",
    "devs = spark.createDataFrame(data, ['id', 'name', 'gender', 'department'])\n",
    "devs.show()\n",
    "devs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f06af409-4f11-4223-ad62-716af4564253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----+----+\n",
      "|department|   F|   M|   T|\n",
      "+----------+----+----+----+\n",
      "|        HR|   1|   1|NULL|\n",
      "|       FIN|NULL|NULL|   1|\n",
      "|        IT|   1|   1|NULL|\n",
      "+----------+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.groupBy('department').pivot('gender').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "01ce8133-b410-41c2-8d75-900ba57837b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----+\n",
      "|department|   M|   F|\n",
      "+----------+----+----+\n",
      "|        HR|   1|   1|\n",
      "|       FIN|NULL|NULL|\n",
      "|        IT|   1|   1|\n",
      "+----------+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we can choose which value of the pivots can be showed as columns\n",
    "devs.groupBy('department').pivot('gender', ['M', 'F']).count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cfc711-f9f7-43fd-8418-ab5710d501c1",
   "metadata": {},
   "source": [
    "# udf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0f44cee3-6e76-40c8-8512-a50a960ffe3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------------+\n",
      "| id|duration|duration_seconds|\n",
      "+---+--------+----------------+\n",
      "|  1|03:25:45|           12345|\n",
      "|  2|01:10:30|            4230|\n",
      "|  3|05:15:20|           18920|\n",
      "+---+--------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(\"1\", \"03:25:45\"), (\"2\", \"01:10:30\"), (\"3\", \"05:15:20\")]\n",
    "df = spark.createDataFrame(data, [\"id\", \"duration\"])\n",
    "\n",
    "def duration_to_seconds(duration_str):\n",
    "    parts = duration_str.split(':')\n",
    "    hours = int(parts[0])\n",
    "    minutes = int(parts[1])\n",
    "    seconds = int(parts[2])\n",
    "    total_seconds = (hours * 3600) + (minutes * 60) + seconds\n",
    "    return total_seconds\n",
    "\n",
    "duration_to_seconds_udf = udf(lambda d: duration_to_seconds(d), returnType=IntegerType())\n",
    "\n",
    "df.withColumn(\"duration_seconds\", duration_to_seconds_udf(\"duration\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aea37a0a-a92f-4f40-a6fe-7aca9e6e1e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reason it works without explicitly registering the UDF is because PySpark automatically \n",
    "# converts certain Python functions into UDFs when they are used within DataFrame transformations.\n",
    "# This behavior is called \"automatic UDF registration.\" \n",
    "\n",
    "# Consider example below:\n",
    "# This demonstrates a scenario where you need to explicitly register the function as a UDF because PySpark cannot automatically\n",
    "# handle the transformation due to the use of external Python libraries or complex logic. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "38694f57-3b03-4b6b-a416-8e3de2f97c4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object, got 'Column'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m df_with_username \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musername\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mextract_username\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memail\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     15\u001b[0m df_with_username\u001b[38;5;241m.\u001b[39mshow()\n",
      "Cell \u001b[0;32mIn[64], line 7\u001b[0m, in \u001b[0;36mextract_username\u001b[0;34m(email)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_username\u001b[39m(email):\n\u001b[0;32m----> 7\u001b[0m     match \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m^([a-zA-Z0-9_.+-]+)@\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memail\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m match:\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/re/__init__.py:166\u001b[0m, in \u001b[0;36mmatch\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmatch\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    164\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Try to apply the pattern at the start of the string, returning\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    a Match object, or None if no match was found.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object, got 'Column'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "data = [(\"1\", \"john.doe@example.com\"), (\"2\", \"jane.smith@example.com\"), (\"3\", \"mike.jones@example.com\")]\n",
    "df = spark.createDataFrame(data, [\"id\", \"email\"])\n",
    "\n",
    "def extract_username(email):\n",
    "    match = re.match(r'^([a-zA-Z0-9_.+-]+)@', email)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df_with_username = df.withColumn(\"username\", extract_username(df.email))\n",
    "\n",
    "df_with_username.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45df5b27-8084-4429-8ec1-72df7b5ad335",
   "metadata": {},
   "source": [
    "# using udf for sql temporary tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "78086171-135f-4252-98d9-04155360c401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+-----+\n",
      "| id|    name|salary|bonus|\n",
      "+---+--------+------+-----+\n",
      "|  1|     Ali|  4000|    0|\n",
      "|  2|   Jafar|  2800|  400|\n",
      "|  3|Mohammad|  3000|  500|\n",
      "|  4|    Abas|     0|    0|\n",
      "|  5|    Mona|  2200|  300|\n",
      "+---+--------+------+-----+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      " |-- bonus: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Ali',4000, 0), (2, 'Jafar', 2800, 400), (3, 'Mohammad', 3000, 500), (4, 'Abas', 0, 0), (5, 'Mona', 2200, 300)]\n",
    "devs = spark.createDataFrame(data, ['id', 'name', 'salary', 'bonus'])\n",
    "devs.show()\n",
    "devs.printSchema()\n",
    "devs.createOrReplaceTempView('devs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "53bcaa6a-8960-4bb0-b2ef-ad0da5e90014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_salary(salary: int, bonus: int) -> int:\n",
    "\n",
    "    return salary + bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6305f95f-080b-4a81-b6aa-b4810bb40c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.sum_salary(salary: int, bonus: int) -> int>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.udf.register(name='udf_sum_salary_sql', f=sum_salary, returnType=IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9f9b5da6-0202-40e5-9b51-097440a21541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+\n",
      "| id|    name|sum_salary|\n",
      "+---+--------+----------+\n",
      "|  1|     Ali|      4000|\n",
      "|  2|   Jafar|      3200|\n",
      "|  3|Mohammad|      3500|\n",
      "|  4|    Abas|         0|\n",
      "|  5|    Mona|      2500|\n",
      "+---+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select id, name,udf_sum_salary_sql(salary, bonus) as sum_salary from devs\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a734af79-3703-4a6c-8bac-0f84f1e1c05a",
   "metadata": {},
   "source": [
    "# window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "54495ea5-284f-486d-96ff-7eac1ecba8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+-----+---------+\n",
      "|      date|         t_id|price|shop_name|\n",
      "+----------+-------------+-----+---------+\n",
      "|2023-01-03|       123123|  227|    edeka|\n",
      "|2023-01-03|       123124|   24|     rewe|\n",
      "|2023-01-03|          234|   24|     rewe|\n",
      "|2023-01-04|       423423|   45|    edeka|\n",
      "|2023-01-05|       424332|   65| eurogida|\n",
      "|2023-01-06|        53454|   85|     aldi|\n",
      "|2023-01-07|      1534543|   43|     rewe|\n",
      "|2023-01-08|      3534434|   32|     rewe|\n",
      "|2023-01-08|     56556332|   22|     rewe|\n",
      "|2023-01-11| 768679823749|   31|     rewe|\n",
      "|2023-01-12|8652438736478|   54|     rewe|\n",
      "|2023-01-13|  93487264823|   41|     rewe|\n",
      "|2023-01-09|       122567|   76|     aldi|\n",
      "+----------+-------------+-----+---------+\n",
      "\n",
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- t_id: string (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      " |-- shop_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transaction_data = [\n",
    "    ('2023-01-03', '123123', 227, 'edeka'),\n",
    "    ('2023-01-03', '123124', 24, 'rewe'),\n",
    "    ('2023-01-03', '234', 24, 'rewe'),\n",
    "    ('2023-01-04', '423423', 45, 'edeka'),\n",
    "    ('2023-01-05', '424332', 65, 'eurogida'),\n",
    "    ('2023-01-06', '53454', 85, 'aldi'),\n",
    "    ('2023-01-07', '1534543', 43, 'rewe'),\n",
    "    ('2023-01-08', '3534434', 32, 'rewe'),\n",
    "    ('2023-01-08', '56556332', 22, 'rewe'),\n",
    "    ('2023-01-11', '768679823749', 31, 'rewe'),\n",
    "    ('2023-01-12', '8652438736478', 54, 'rewe'),\n",
    "    ('2023-01-13', '93487264823', 41, 'rewe'),\n",
    "    ('2023-01-09', '122567', 76, 'aldi'),\n",
    "]\n",
    "\n",
    "schema = StructType() \\\n",
    "    .add('date', StringType()) \\\n",
    "    .add('t_id', StringType()) \\\n",
    "    .add('price', IntegerType()) \\\n",
    "    .add('shop_name', StringType())\n",
    "\n",
    "transactions = spark.createDataFrame(\n",
    "    data=transaction_data,\n",
    "    schema=schema\n",
    ")\n",
    "\n",
    "transactions.show()\n",
    "transactions.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85a7d3f-3d0e-4586-bf95-17a854ae2406",
   "metadata": {},
   "source": [
    "# row_number() rank() dense_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c5b0bc1b-0b80-4e64-a27d-079ba73a6b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = Window.orderBy('date', 'price').partitionBy('shop_name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f4a28949-9111-4662-bae2-ea58c461bc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-----+-----+----+----+-----+-------------------+----+----+----+-------+\n",
      "|      date|shop_name|price|first| nth|rank|dense|       percent_rank|lead| lag|last|row_num|\n",
      "+----------+---------+-----+-----+----+----+-----+-------------------+----+----+----+-------+\n",
      "|2023-01-06|     aldi|   85|   85|NULL|   1|    1|                0.0|  76|NULL|  85|      1|\n",
      "|2023-01-09|     aldi|   76|   85|NULL|   2|    2|                1.0|NULL|  85|  76|      2|\n",
      "|2023-01-03|    edeka|  227|  227|NULL|   1|    1|                0.0|  45|NULL| 227|      1|\n",
      "|2023-01-04|    edeka|   45|  227|NULL|   2|    2|                1.0|NULL| 227|  45|      2|\n",
      "|2023-01-05| eurogida|   65|   65|NULL|   1|    1|                0.0|NULL|NULL|  65|      1|\n",
      "|2023-01-03|     rewe|   24|   24|NULL|   1|    1|                0.0|  24|NULL|  24|      1|\n",
      "|2023-01-03|     rewe|   24|   24|NULL|   1|    1|                0.0|  43|  24|  24|      2|\n",
      "|2023-01-07|     rewe|   43|   24|NULL|   3|    2| 0.2857142857142857|  22|  24|  43|      3|\n",
      "|2023-01-08|     rewe|   22|   24|NULL|   4|    3|0.42857142857142855|  32|  43|  22|      4|\n",
      "|2023-01-08|     rewe|   32|   24|  32|   5|    4| 0.5714285714285714|  31|  22|  32|      5|\n",
      "|2023-01-11|     rewe|   31|   24|  32|   6|    5| 0.7142857142857143|  54|  32|  31|      6|\n",
      "|2023-01-12|     rewe|   54|   24|  32|   7|    6| 0.8571428571428571|  41|  31|  54|      7|\n",
      "|2023-01-13|     rewe|   41|   24|  32|   8|    7|                1.0|NULL|  54|  41|      8|\n",
      "+----------+---------+-----+-----+----+----+-----+-------------------+----+----+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactions.select('date', 'shop_name', 'price') \\\n",
    "    .withColumn('first', first('price').over(window)) \\\n",
    "    .withColumn('nth', nth_value('price', 5).over(window)) \\\n",
    "    .withColumn('rank', rank().over(window)) \\\n",
    "    .withColumn('dense', dense_rank().over(window)) \\\n",
    "    .withColumn('percent_rank', percent_rank().over(window)) \\\n",
    "    .withColumn('lead', lead('price', 1).over(window)) \\\n",
    "    .withColumn('lag', lag('price', 1).over(window)) \\\n",
    "    .withColumn('last', last('price').over(window)) \\\n",
    "    .withColumn('row_num', row_number().over(window)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad6a952-3783-48ae-aa58-74b8b62b4353",
   "metadata": {},
   "source": [
    "# apply map() on DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "96f95609-7743-48c9-8d50-0f3347acc70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|first_name| last_name|\n",
      "+----------+----------+\n",
      "|     Oveys|Safarnejad|\n",
      "|       Ala|   Nourani|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [('Oveys', 'Safarnejad'), ('Ala', 'Nourani')]\n",
    "schema = StructType().add('first_name', StringType()).add('last_name', StringType())\n",
    "\n",
    "persons = spark.createDataFrame(data, schema)\n",
    "persons.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f9705154-0aa2-405e-bd39-d6c8bd103e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|       full_name|\n",
      "+----------------+\n",
      "|Oveys Safarnejad|\n",
      "|     Ala Nourani|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dataframes don't support map() on their rows\n",
    "# You have to convert it to a RDD and then apply map() on them, finally you can reconvert it to dataframe.\n",
    "persons_maped_rdd = persons.rdd.map(lambda x: (x[0] + ' ' + x[1],))\n",
    "persons_maped_rdd.toDF(schema=['full_name']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74653fdc-472b-49fc-bc09-ec0f072e829e",
   "metadata": {},
   "source": [
    "# partition data on write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5c7a7f5f-9fa2-4e37-8561-13f9d4fe809e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+----------+\n",
      "| id|    name|gender|department|\n",
      "+---+--------+------+----------+\n",
      "|  1|     Ali|     M|        IT|\n",
      "|  2|   Jafar|     F|        HR|\n",
      "|  3|Mohammad|     M|      NULL|\n",
      "|  4|    Abas|     F|        IT|\n",
      "|  5|    Mona|     T|       FIN|\n",
      "+---+--------+------+----------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Ali','M', 'IT'), (2, 'Jafar', 'F', 'HR'), (3, 'Mohammad', 'M', None), (4, 'Abas', 'F', 'IT'), (5, 'Mona', 'T', 'FIN')]\n",
    "devs = spark.createDataFrame(data, ['id', 'name', 'gender', 'department'])\n",
    "devs.show()\n",
    "devs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "caaff26d-8bce-4a91-a94f-188827bd562f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "devs.write.parquet('./devs/parquests', partitionBy='department', mode='overwrite')\n",
    "# This partionBy parameter will devide data into different sections based on department column value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bc89022d-e1fd-4652-8e98-b902602b1877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+----------+\n",
      "| id|    name|gender|department|\n",
      "+---+--------+------+----------+\n",
      "|  3|Mohammad|     M|      NULL|\n",
      "|  2|   Jafar|     F|        HR|\n",
      "|  4|    Abas|     F|        IT|\n",
      "|  5|    Mona|     T|       FIN|\n",
      "|  1|     Ali|     M|        IT|\n",
      "+---+--------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.parquet('./devs/parquests').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ac304646-decd-41bf-85ae-29c43d06c6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+\n",
      "| id| name|gender|\n",
      "+---+-----+------+\n",
      "|  2|Jafar|     F|\n",
      "+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.parquet('./devs/parquests/department=HR').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df22ff69-5a3c-4270-a445-233a1a278893",
   "metadata": {},
   "source": [
    "# from_json()\n",
    "##### it will accept a column of type string and convert it to MapType or StructType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aefaefe4-3cb7-4219-9576-1208d45a5ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- props: string (nullable = true)\n",
      "\n",
      "+-----+----------------------------------+\n",
      "|name |props                             |\n",
      "+-----+----------------------------------+\n",
      "|Oveys|{\"age\": 31, \"hair_color\": \"black\"}|\n",
      "|Ala  |{\"age\": 32, \"hair_color\": \"pink\"} |\n",
      "+-----+----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    ('Oveys', '{\"age\": 31, \"hair_color\": \"black\"}'), \n",
    "    ('Ala', '{\"age\": 32, \"hair_color\": \"pink\"}'), \n",
    "]\n",
    "\n",
    "persons = spark.createDataFrame(data, schema=['name', 'props'])\n",
    "\n",
    "persons.printSchema()\n",
    "persons.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e599b147-af62-4df5-9ff2-dbee3ac289da",
   "metadata": {},
   "source": [
    "### The question is to convert values in the map type column into different columns ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "98731e04-9c3b-4eac-b661-010fadd9d845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+---+\n",
      "| name|hair_color|age|\n",
      "+-----+----------+---+\n",
      "|Oveys|     black| 31|\n",
      "|  Ala|      pink| 32|\n",
      "+-----+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "keys = persons.select(\n",
    "    explode(\n",
    "        map_keys(\n",
    "            from_json(\n",
    "                'props',\n",
    "                schema=MapType(StringType(),StringType())\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "exprs = [from_json(col('props'),schema=MapType(StringType(),StringType())).getItem(k).alias(k) for k in keys]\n",
    "persons.select('name', *exprs).show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a7fe0b7e-155c-41f1-9320-5430b3aabc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+\n",
      "| name|age|hair_color|\n",
      "+-----+---+----------+\n",
      "|Oveys| 31|     black|\n",
      "|  Ala| 32|      pink|\n",
      "+-----+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this way is more optimized since it is not calling collect() which may cause performance issue on large datasets.\n",
    "\n",
    "json_schema = spark.read.json(persons.rdd.map(lambda r: r.props)).schema\n",
    "persons = persons.withColumn(\"_c\", from_json(\"props\", json_schema))\n",
    "persons.select(\"name\", \"_c.*\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e0dc3f-f18f-47f5-9b4b-d3ad1fdf9959",
   "metadata": {},
   "source": [
    "# to_json()\n",
    "###### It will convert a column from MapType or StructType to json string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "30dcb62e-1fe1-4640-8726-7ce871c50881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- props: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: long (valueContainsNull = true)\n",
      "\n",
      "+-----+-------------------------------+\n",
      "|name |props                          |\n",
      "+-----+-------------------------------+\n",
      "|Oveys|{age -> 31, hair_color -> NULL}|\n",
      "|Ala  |{age -> 32, hair_color -> NULL}|\n",
      "+-----+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    ('Oveys', {\"age\": 31, \"hair_color\": \"black\"}), \n",
    "    ('Ala', {\"age\": 32, \"hair_color\": \"pink\"}), \n",
    "]\n",
    "\n",
    "persons = spark.createDataFrame(data, schema=['name', 'props'])\n",
    "\n",
    "persons.printSchema()\n",
    "persons.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fb352b43-842e-44cf-8f1e-fea8e52413bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------------+----------------------------+\n",
      "|name |props                          |json_props                  |\n",
      "+-----+-------------------------------+----------------------------+\n",
      "|Oveys|{age -> 31, hair_color -> NULL}|{\"age\":31,\"hair_color\":null}|\n",
      "|Ala  |{age -> 32, hair_color -> NULL}|{\"age\":32,\"hair_color\":null}|\n",
      "+-----+-------------------------------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons.withColumn('json_props', to_json('props')).show(truncate=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3378f6-fcc3-4739-bd4f-7ee7760b0982",
   "metadata": {},
   "source": [
    "# json_tuple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fc5829c0-fddc-40b8-9cb1-9eafc26b9125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- props: string (nullable = true)\n",
      "\n",
      "+-----+------------------------------------------------------------------------+\n",
      "|name |props                                                                   |\n",
      "+-----+------------------------------------------------------------------------+\n",
      "|Oveys|{\"personal_info\": {\"hair_color\":\"black\", \"eye_color\":\"black\"}, \"age\":31}|\n",
      "|Ala  |{\"personal_info\":{\"hair_color\":\"brown\", \"eye_color\":\"brown\"}, \"age\":32} |\n",
      "+-----+------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    ('Oveys', '{\"personal_info\": {\"hair_color\":\"black\", \"eye_color\":\"black\"}, \"age\":31}'),\n",
    "    ('Ala', '{\"personal_info\":{\"hair_color\":\"brown\", \"eye_color\":\"brown\"}, \"age\":32}')\n",
    "]\n",
    "schema = StructType(\n",
    "    [StructField('name', StringType()), StructField('props', StringType())]\n",
    ")\n",
    "\n",
    "persons = spark.createDataFrame(data, schema)\n",
    "\n",
    "persons.printSchema()\n",
    "persons.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "30294840-daa7-4e50-ad12-2b3b46deed46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "|Oveys| 31|\n",
      "|  Ala| 32|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons.select('name', json_tuple('props', 'age').alias('age')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942eb26b-222a-42dc-8882-17b3c2a19db1",
   "metadata": {},
   "source": [
    "# get_json_object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "45c7c987-3eb7-47b2-ae1a-1d721fed0303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "| name| hair|\n",
      "+-----+-----+\n",
      "|Oveys|black|\n",
      "|  Ala|brown|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons.select('name', sql_functions.get_json_object('props', '$.personal_info.hair_color').alias('hair')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788b81e0-cdc2-42a1-934b-9d403f6fdb6c",
   "metadata": {},
   "source": [
    "#### but how to extract all the keys as columns?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5baf6a2-4652-4eed-a331-09ab0e571bac",
   "metadata": {},
   "source": [
    "## method 1 (manual - based on keys) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9d711a5e-94f7-4276-9bb0-6c163efea2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---------+----------+\n",
      "| name|age|eye_color|hair_color|\n",
      "+-----+---+---------+----------+\n",
      "|Oveys| 31|    black|     black|\n",
      "|  Ala| 32|    brown|     brown|\n",
      "+-----+---+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "json_schema = spark.read.json(persons.rdd.map(lambda r: r.props)).schema\n",
    "persons.withColumn(\"_c\", from_json(\"props\", json_schema)).select(\"name\", \"_c.age\", \"_c.personal_info.*\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98966563-cca9-4c06-b4d1-5c3ebf1cedb6",
   "metadata": {},
   "source": [
    "## method 2 (Dynamic key extracting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a66f8694-5dab-449a-ad0b-8677f8e32205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schema_all_keys(base_schema: StructType, keys: list=[], parent_key=\"\") -> list:\n",
    "    for key in base_schema.fields:\n",
    "        if isinstance(key.dataType, StructType):\n",
    "            new_parent_key = f\"{parent_key}.{key.name}\" if parent_key else key.name\n",
    "            get_schema_all_keys(key.dataType, keys, new_parent_key)\n",
    "        else:\n",
    "            full_key = f\"{parent_key}.{key.name}\" if parent_key else key.name\n",
    "            keys.append(full_key)\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9b7c9cc9-617a-425a-97f8-e49e66748878",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+---+---------+----------+----+\n",
      "| name|               props|age|eye_color|hair_color|size|\n",
      "+-----+--------------------+---+---------+----------+----+\n",
      "|Oveys|{\"personal_info\":...| 31|    black|     black|  80|\n",
      "|  Ala|{\"personal_info\":...| 32|    brown|     brown|NULL|\n",
      "+-----+--------------------+---+---------+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    ('Oveys', '{\"personal_info\": {\"hair_color\":\"black\", \"eye_color\":\"black\", \"size\":80}, \"age\":31}'),\n",
    "    ('Ala', '{\"personal_info\":{\"hair_color\":\"brown\", \"eye_color\":\"brown\"}, \"age\":32}')\n",
    "]\n",
    "\n",
    "persons = spark.createDataFrame(data, schema=['name', 'props'])\n",
    "\n",
    "props_schema = spark.read.json(persons.rdd.map(lambda r: r.props)).schema\n",
    "keys = get_schema_all_keys(props_schema)\n",
    "for key in keys:\n",
    "    col_name = key.split('.')[-1]\n",
    "    persons = persons.withColumn(col_name, sql_functions.expr(f\"get_json_object(props, '$.{key}')\"))\n",
    "\n",
    "persons.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e5046f-3b72-48ec-9866-f5b2867b1583",
   "metadata": {},
   "source": [
    "# date functions\n",
    "##### default date format is yyyy-MM-dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5d23ff1-2431-44e8-81a4-80125ec93a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+----------+\n",
      "| id|    name|gender|department|\n",
      "+---+--------+------+----------+\n",
      "|  1|     Ali|     M|        IT|\n",
      "|  2|   Jafar|     F|        HR|\n",
      "|  3|Mohammad|     M|      NULL|\n",
      "|  4|    Abas|     F|        IT|\n",
      "|  5|    Mona|     T|       FIN|\n",
      "+---+--------+------+----------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Ali','M', 'IT'), (2, 'Jafar', 'F', 'HR'), (3, 'Mohammad', 'M', None), (4, 'Abas', 'F', 'IT'), (5, 'Mona', 'T', 'FIN')]\n",
    "devs = spark.createDataFrame(data, ['id', 'name', 'gender', 'department'])\n",
    "devs.show()\n",
    "devs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32c48282-44d0-48cf-99a2-4baee7ea378b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+----------+----------+\n",
      "| id|    name|gender|department|     today|\n",
      "+---+--------+------+----------+----------+\n",
      "|  1|     Ali|     M|        IT|2024-04-05|\n",
      "|  2|   Jafar|     F|        HR|2024-04-05|\n",
      "|  3|Mohammad|     M|      NULL|2024-04-05|\n",
      "|  4|    Abas|     F|        IT|2024-04-05|\n",
      "|  5|    Mona|     T|       FIN|2024-04-05|\n",
      "+---+--------+------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs = devs.withColumn('today', sql_functions.current_date())\n",
    "devs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "664c6906-9a00-43e8-8b56-9b05f596df6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+----------+----------+----------+\n",
      "| id|    name|gender|department|     today|Unformated|\n",
      "+---+--------+------+----------+----------+----------+\n",
      "|  1|     Ali|     M|        IT|2024-04-05|      2024|\n",
      "|  2|   Jafar|     F|        HR|2024-04-05|      2024|\n",
      "|  3|Mohammad|     M|      NULL|2024-04-05|      2024|\n",
      "|  4|    Abas|     F|        IT|2024-04-05|      2024|\n",
      "|  5|    Mona|     T|       FIN|2024-04-05|      2024|\n",
      "+---+--------+------+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.withColumn('Unformated', sql_functions.date_format(col('today'), 'yyyy')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbbf735b-3e5f-4626-ae57-2401c9525ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+----------+----------+----------+\n",
      "| id|    name|gender|department|     today|  lit_date|\n",
      "+---+--------+------+----------+----------+----------+\n",
      "|  1|     Ali|     M|        IT|2024-04-05|1992-07-05|\n",
      "|  2|   Jafar|     F|        HR|2024-04-05|1992-07-05|\n",
      "|  3|Mohammad|     M|      NULL|2024-04-05|1992-07-05|\n",
      "|  4|    Abas|     F|        IT|2024-04-05|1992-07-05|\n",
      "|  5|    Mona|     T|       FIN|2024-04-05|1992-07-05|\n",
      "+---+--------+------+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs = devs.withColumn('lit_date', sql_functions.to_date(lit('05.07.1992'), 'dd.MM.yyyy'))\n",
    "devs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fad7a5d0-b184-406a-8952-5732f23eba87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+----------+----------+----------+-----+\n",
      "| id|    name|gender|department|     today|  lit_date|  age|\n",
      "+---+--------+------+----------+----------+----------+-----+\n",
      "|  1|     Ali|     M|        IT|2024-04-05|1992-07-05|11597|\n",
      "|  2|   Jafar|     F|        HR|2024-04-05|1992-07-05|11597|\n",
      "|  3|Mohammad|     M|      NULL|2024-04-05|1992-07-05|11597|\n",
      "|  4|    Abas|     F|        IT|2024-04-05|1992-07-05|11597|\n",
      "|  5|    Mona|     T|       FIN|2024-04-05|1992-07-05|11597|\n",
      "+---+--------+------+----------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.withColumn('age', sql_functions.date_diff('today', 'lit_date')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d186a837-3898-42af-99f4-e00846d5ecfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+----------+----------+----------+-------------+\n",
      "| id|    name|gender|department|     today|  lit_date|month_between|\n",
      "+---+--------+------+----------+----------+----------+-------------+\n",
      "|  1|     Ali|     M|        IT|2024-04-05|1992-07-05|        381.0|\n",
      "|  2|   Jafar|     F|        HR|2024-04-05|1992-07-05|        381.0|\n",
      "|  3|Mohammad|     M|      NULL|2024-04-05|1992-07-05|        381.0|\n",
      "|  4|    Abas|     F|        IT|2024-04-05|1992-07-05|        381.0|\n",
      "|  5|    Mona|     T|       FIN|2024-04-05|1992-07-05|        381.0|\n",
      "+---+--------+------+----------+----------+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.withColumn('month_between', sql_functions.months_between('today', 'lit_date')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54f03a02-4ff7-4ffb-a6ef-f36c02388129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+----------+----------+----------+----------+\n",
      "| id|    name|gender|department|     today|  lit_date| add_month|\n",
      "+---+--------+------+----------+----------+----------+----------+\n",
      "|  1|     Ali|     M|        IT|2024-04-05|1993-08-18|2024-07-05|\n",
      "|  2|   Jafar|     F|        HR|2024-04-05|1993-08-18|2024-07-05|\n",
      "|  3|Mohammad|     M|      NULL|2024-04-05|1993-08-18|2024-07-05|\n",
      "|  4|    Abas|     F|        IT|2024-04-05|1993-08-18|2024-07-05|\n",
      "|  5|    Mona|     T|       FIN|2024-04-05|1993-08-18|2024-07-05|\n",
      "+---+--------+------+----------+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.withColumn('add_month', sql_functions.add_months('today', 3)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c91b270-0c94-4775-b3f1-647e61ac7aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+----------+----------+----------+----------+\n",
      "| id|    name|gender|department|     today|  lit_date| sub_month|\n",
      "+---+--------+------+----------+----------+----------+----------+\n",
      "|  1|     Ali|     M|        IT|2024-04-05|1992-07-05|2024-02-05|\n",
      "|  2|   Jafar|     F|        HR|2024-04-05|1992-07-05|2024-02-05|\n",
      "|  3|Mohammad|     M|      NULL|2024-04-05|1992-07-05|2024-02-05|\n",
      "|  4|    Abas|     F|        IT|2024-04-05|1992-07-05|2024-02-05|\n",
      "|  5|    Mona|     T|       FIN|2024-04-05|1992-07-05|2024-02-05|\n",
      "+---+--------+------+----------+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.withColumn('sub_month', sql_functions.add_months('today', -2)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab7688f1-2caf-472c-8644-5e92e1b605ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+----------+----------+----------+----------+\n",
      "| id|    name|gender|department|     today|  lit_date|  days_add|\n",
      "+---+--------+------+----------+----------+----------+----------+\n",
      "|  1|     Ali|     M|        IT|2024-04-05|1992-07-05|2024-04-15|\n",
      "|  2|   Jafar|     F|        HR|2024-04-05|1992-07-05|2024-04-15|\n",
      "|  3|Mohammad|     M|      NULL|2024-04-05|1992-07-05|2024-04-15|\n",
      "|  4|    Abas|     F|        IT|2024-04-05|1992-07-05|2024-04-15|\n",
      "|  5|    Mona|     T|       FIN|2024-04-05|1992-07-05|2024-04-15|\n",
      "+---+--------+------+----------+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.withColumn('days_add', sql_functions.date_add('today', 10)).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f38def-0f8c-4594-8417-c6a12bb329d2",
   "metadata": {},
   "source": [
    "#### dayOfYear(), dayOfWeek(), dayOfYear(), days(), month(), year() are other functions ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3b0a16-ae29-47b0-812f-009fa7153f9c",
   "metadata": {},
   "source": [
    "## default TimestampType format is yyyy-MM-dd HH:mm:ss.SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e96ccde-982e-4790-97f8-29e72f678143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.range(4)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a975247-3d63-48a3-946d-3a92105b3e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------------+\n",
      "|id |timestamp                 |\n",
      "+---+--------------------------+\n",
      "|0  |2024-04-05 15:48:39.067556|\n",
      "|1  |2024-04-05 15:48:39.067556|\n",
      "|2  |2024-04-05 15:48:39.067556|\n",
      "|3  |2024-04-05 15:48:39.067556|\n",
      "+---+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('timestamp', sql_functions.current_timestamp())\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a25ab9b-0100-4afc-97a9-c2acbbd2d65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------------+----------------------+\n",
      "|id |timestamp                 |from_lit              |\n",
      "+---+--------------------------+----------------------+\n",
      "|0  |2024-04-05 15:48:39.460769|1993-08-18 12:00:04.04|\n",
      "|1  |2024-04-05 15:48:39.460769|1993-08-18 12:00:04.04|\n",
      "|2  |2024-04-05 15:48:39.460769|1993-08-18 12:00:04.04|\n",
      "|3  |2024-04-05 15:48:39.460769|1993-08-18 12:00:04.04|\n",
      "+---+--------------------------+----------------------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = false)\n",
      " |-- timestamp: timestamp (nullable = false)\n",
      " |-- from_lit: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('from_lit', sql_functions.to_timestamp(lit('08-18-1993 12:00:04.04'), format='MM-dd-yyyy HH:mm:ss.SS'))\n",
    "df.show(truncate=False)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f232e525-e352-4d1d-9032-369112116d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------------+----------------------+----+-------+-------+\n",
      "|id |timestamp                 |from_lit              |hour|minutes|seconds|\n",
      "+---+--------------------------+----------------------+----+-------+-------+\n",
      "|0  |2024-04-05 15:48:40.526679|1993-08-18 12:00:04.04|12  |0      |4      |\n",
      "|1  |2024-04-05 15:48:40.526679|1993-08-18 12:00:04.04|12  |0      |4      |\n",
      "|2  |2024-04-05 15:48:40.526679|1993-08-18 12:00:04.04|12  |0      |4      |\n",
      "|3  |2024-04-05 15:48:40.526679|1993-08-18 12:00:04.04|12  |0      |4      |\n",
      "+---+--------------------------+----------------------+----+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "    '*',\n",
    "    sql_functions.hour('from_lit').alias('hour'),\n",
    "    sql_functions.minute('from_lit').alias('minutes'),\n",
    "    sql_functions.second('from_lit').alias('seconds'),\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0069a39-1166-4718-9fbf-72e31d39a06a",
   "metadata": {},
   "source": [
    "# aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f1fcf45-472c-4b60-9b6e-818197ea9086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+----------+------+\n",
      "| id|    name|gender|department|salary|\n",
      "+---+--------+------+----------+------+\n",
      "|  1|     Ali|     M|        IT|  1200|\n",
      "|  2|   Jafar|     F|        HR| 20000|\n",
      "|  3|Mohammad|     M|      NULL| 30000|\n",
      "|  4|    Abas|     F|        IT|   200|\n",
      "|  5|    Mona|     T|       FIN|  6000|\n",
      "+---+--------+------+----------+------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Ali','M', 'IT', 1200), (2, 'Jafar', 'F', 'HR', 20000), (3, 'Mohammad', 'M', None, 30000), (4, 'Abas', 'F', 'IT',  200), (5, 'Mona', 'T', 'FIN', 6000)]\n",
    "devs = spark.createDataFrame(data, ['id', 'name', 'gender', 'department', 'salary'])\n",
    "devs.show()\n",
    "devs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5782c02f-eb03-4583-9c68-c25288d8f9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+\n",
      "|approx_count_distinct(department)|\n",
      "+---------------------------------+\n",
      "|                                3|\n",
      "+---------------------------------+\n",
      "\n",
      "+-----------------------------+\n",
      "|approx_count_distinct(gender)|\n",
      "+-----------------------------+\n",
      "|                            3|\n",
      "+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.select(sql_functions.approx_count_distinct('department')).show()\n",
    "devs.select(sql_functions.approx_count_distinct('gender')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fc05ca1-621a-480d-b0c0-ca5740bc3fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|avg(salary)|\n",
      "+-----------+\n",
      "|    11480.0|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.select(sql_functions.avg('salary')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7fbbda0-87fe-4b07-91a9-20adc852558b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+\n",
      "|collect_list(salary)           |\n",
      "+-------------------------------+\n",
      "|[1200, 20000, 30000, 200, 6000]|\n",
      "+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.select(sql_functions.collect_list('salary')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "377443fb-49f0-4e2f-875c-b6188931e389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+\n",
      "|collect_set(salary)            |\n",
      "+-------------------------------+\n",
      "|[1200, 30000, 6000, 20000, 200]|\n",
      "+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.select(sql_functions.collect_set('salary')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "694be66e-ff3a-449e-a93c-530bdd3397c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 34:==============>                                           (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|count(DISTINCT department)|\n",
      "+--------------------------+\n",
      "|3                         |\n",
      "+--------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "devs.select(sql_functions.count_distinct('department')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6cb075d-9466-45d2-a077-84d239a8f1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|count(department)|\n",
      "+-----------------+\n",
      "|4                |\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.select(sql_functions.count('department')).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cfdbdb-caa0-4dd0-a1ef-9e0921588fdf",
   "metadata": {},
   "source": [
    "# Errors and Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28c7d96b-94a6-42f6-8d0d-5e363e9735f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+--------------------+--------+-------+----------+------------+-----+\n",
      "|Part_Number|        Name|         Description|Quantity|    EOL|Unit_Price|Manufacturer|avail|\n",
      "+-----------+------------+--------------------+--------+-------+----------+------------+-----+\n",
      "|   12312312|   'sdadasd'|'sadas asdsad asdas'|      12|01-2026|       123| 'company 1'|    1|\n",
      "|   45645645|    'qwerty'|'Lorem ipsum dolo...|      30|06-2025|        89| 'company 2'|    1|\n",
      "|   78978978|    'foobar'|'Consectetur adip...|      25|09-2027|        55| 'company 3'|    0|\n",
      "|   10101010|       'xyz'|'Sed do eiusmod t...|      18|04-2024|        72| 'company 4'|    1|\n",
      "|   11111111|    'abcdef'|'Ut enim ad minim...|      40|12-2026|       105| 'company 5'|    1|\n",
      "|   12121212|    'ghijkl'|'Quis nostrud exe...|      20|03-2025|        95| 'company 6'|    1|\n",
      "|   13131313|    'mnopqr'|'Duis aute irure ...|      15|08-2023|        80| 'company 7'|    1|\n",
      "|   14141414|    'stuvwx'|'Excepteur sint o...|      35|07-2026|        67| 'company 8'|    1|\n",
      "|   15151515|  'yzabcdef'|'Sunt in culpa qu...|      22|11-2025|       120| 'company 9'|    1|\n",
      "|   16161616|'ghijklmnop'|'Lorem ipsum dolo...|      28|02-2026|        85|'company 10'|    1|\n",
      "|   17171717|    'qrstuv'|'Consectetur adip...|      32|10-2027|        60|'company 11'|    0|\n",
      "|   18181818|      'wxyz'|'Sed do eiusmod t...|      19|05-2024|        75|'company 12'|    1|\n",
      "|   19191919|    '123456'|'Ut enim ad minim...|      45|01-2028|       110|'company 13'|    1|\n",
      "|   20202020|    '789012'|'Quis nostrud exe...|      24|09-2025|       100|'company 14'|    1|\n",
      "|   21212121|    '345678'|'Duis aute irure ...|      17|06-2023|        90|'company 15'|    1|\n",
      "|   22222222|    '901234'|'Excepteur sint o...|      38|08-2026|        65|'company 16'|    1|\n",
      "|   23232323|    '567890'|'Sunt in culpa qu...|      21|04-2025|       115|'company 17'|    1|\n",
      "|   24242424|    '012345'|'Lorem ipsum dolo...|      29|12-2025|        82|'company 18'|    1|\n",
      "|   25252525|    '678901'|'Consectetur adip...|      33|03-2027|        57|'company 19'|    0|\n",
      "|   26262626|    '234567'|'Sed do eiusmod t...|      16|11-2024|        77|'company 20'|    1|\n",
      "+-----------+------------+--------------------+--------+-------+----------+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----------+----+-----------+--------+---+----------+------------+-----+\n",
      "|Part_Number|Name|Description|Quantity|EOL|Unit_Price|Manufacturer|avail|\n",
      "+-----------+----+-----------+--------+---+----------+------------+-----+\n",
      "|          0|   0|          0|       0|  1|         1|           1|    1|\n",
      "+-----------+----+-----------+--------+---+----------+------------+-----+\n",
      "\n",
      "+-----------+------------+--------------------+--------+-------+----------+------------+-----+\n",
      "|Part_Number|        Name|         Description|Quantity|    EOL|Unit_Price|Manufacturer|avail|\n",
      "+-----------+------------+--------------------+--------+-------+----------+------------+-----+\n",
      "|   11111111|    'abcdef'|'Ut enim ad minim...|      40|12-2026|       105| 'company 5'|    1|\n",
      "|   12121212|    'ghijkl'|'Quis nostrud exe...|      20|03-2025|        95| 'company 6'|    1|\n",
      "|   14141414|    'stuvwx'|'Excepteur sint o...|      35|07-2026|        67| 'company 8'|    1|\n",
      "|   15151515|  'yzabcdef'|'Sunt in culpa qu...|      22|11-2025|       120| 'company 9'|    1|\n",
      "|   16161616|'ghijklmnop'|'Lorem ipsum dolo...|      28|02-2026|        85|'company 10'|    1|\n",
      "|   17171717|    'qrstuv'|'Consectetur adip...|      32|10-2027|        60|'company 11'|    0|\n",
      "|   20202020|    '789012'|'Quis nostrud exe...|      24|09-2025|       100|'company 14'|    1|\n",
      "|   22222222|    '901234'|'Excepteur sint o...|      38|08-2026|        65|'company 16'|    1|\n",
      "|   23232323|    '567890'|'Sunt in culpa qu...|      21|04-2025|       115|'company 17'|    1|\n",
      "|   24242424|    '012345'|'Lorem ipsum dolo...|      29|12-2025|        82|'company 18'|    1|\n",
      "|   25252525|    '678901'|'Consectetur adip...|      33|03-2027|        57|'company 19'|    0|\n",
      "|   28282828|    '456789'|'Quis nostrud exe...|      23|05-2025|       105| 'company 2'|    1|\n",
      "|   30303030|    '678901'|'Excepteur sint o...|      36|10-2026|        62| 'company 4'|    1|\n",
      "|   31313131|    '234567'|'Sunt in culpa qu...|      25|02-2025|       120| 'company 5'|    1|\n",
      "|   32323232|    '890123'|'Lorem ipsum dolo...|      31|12-2026|        85| 'company 6'|    1|\n",
      "|   33333333|    '456789'|'Consectetur adip...|      34|07-2027|        60| 'company 7'|    0|\n",
      "|   35353535|    '678901'|'Ut enim ad minim...|      40|01-2029|       110| 'company 9'|    1|\n",
      "|   38383838|    '456789'|'Excepteur sint o...|      24|08-2026|        65|'company 12'|    1|\n",
      "|   39393939|    '012345'|'Sunt in culpa qu...|      28|04-2025|       115|'company 13'|    1|\n",
      "|   40404040|    '678901'|'Lorem ipsum dolo...|      32|12-2025|        82|'company 14'|    1|\n",
      "|   41414141|    '234567'|'Consectetur adip...|      22|03-2027|        57|'company 15'|    0|\n",
      "|   44444444|    '012345'|'Quis nostrud exe...|      23|05-2025|       105|'company 18'|    1|\n",
      "|   45645645|    'qwerty'|'Lorem ipsum dolo...|      30|06-2025|        89| 'company 2'|    1|\n",
      "|   46464646|    '234567'|'Excepteur sint o...|      36|10-2026|        62|'company 20'|    1|\n",
      "|   47474747|    '890123'|'Sunt in culpa qu...|      25|02-2025|       120| 'company 1'|    1|\n",
      "|   48484848|    '456789'|'Lorem ipsum dolo...|      31|12-2026|        85| 'company 2'|    1|\n",
      "|   49494949|    '012345'|'Consectetur adip...|      34|07-2027|        60| 'company 3'|    0|\n",
      "|   78978978|    'foobar'|'Consectetur adip...|      25|09-2027|        55| 'company 3'|    0|\n",
      "+-----------+------------+--------------------+--------+-------+----------+------------+-----+\n",
      "\n",
      "+-----------+------------+--------------------+--------+-------+----------+------------+-----+\n",
      "|Part_Number|        Name|         Description|Quantity|    EOL|Unit_Price|Manufacturer|avail|\n",
      "+-----------+------------+--------------------+--------+-------+----------+------------+-----+\n",
      "|   11111111|    'abcdef'|'Ut enim ad minim...|      40|12-2026|       105| 'company 5'|    1|\n",
      "|   12121212|    'ghijkl'|'Quis nostrud exe...|      20|03-2025|        95| 'company 6'|    1|\n",
      "|   14141414|    'stuvwx'|'Excepteur sint o...|      35|07-2026|        67| 'company 8'|    1|\n",
      "|   15151515|  'yzabcdef'|'Sunt in culpa qu...|      22|11-2025|       120| 'company 9'|    1|\n",
      "|   16161616|'ghijklmnop'|'Lorem ipsum dolo...|      28|02-2026|        85|'company 10'|    1|\n",
      "|   17171717|    'qrstuv'|'Consectetur adip...|      32|10-2027|        60|'company 11'|    0|\n",
      "|   20202020|    '789012'|'Quis nostrud exe...|      24|09-2025|       100|'company 14'|    1|\n",
      "|   22222222|    '901234'|'Excepteur sint o...|      38|08-2026|        65|'company 16'|    1|\n",
      "|   23232323|    '567890'|'Sunt in culpa qu...|      21|04-2025|       115|'company 17'|    1|\n",
      "|   24242424|    '012345'|'Lorem ipsum dolo...|      29|12-2025|        82|'company 18'|    1|\n",
      "|   25252525|    '678901'|'Consectetur adip...|      33|03-2027|        57|'company 19'|    0|\n",
      "|   28282828|    '456789'|'Quis nostrud exe...|      23|05-2025|       105| 'company 2'|    1|\n",
      "|   30303030|    '678901'|'Excepteur sint o...|      36|10-2026|        62| 'company 4'|    1|\n",
      "|   31313131|    '234567'|'Sunt in culpa qu...|      25|02-2025|       120| 'company 5'|    1|\n",
      "|   32323232|    '890123'|'Lorem ipsum dolo...|      31|12-2026|        85| 'company 6'|    1|\n",
      "|   33333333|    '456789'|'Consectetur adip...|      34|07-2027|        60| 'company 7'|    0|\n",
      "|   35353535|    '678901'|'Ut enim ad minim...|      40|01-2029|       110| 'company 9'|    1|\n",
      "|   38383838|    '456789'|'Excepteur sint o...|      24|08-2026|        65|'company 12'|    1|\n",
      "|   39393939|    '012345'|'Sunt in culpa qu...|      28|04-2025|       115|'company 13'|    1|\n",
      "|   40404040|    '678901'|'Lorem ipsum dolo...|      32|12-2025|        82|'company 14'|    1|\n",
      "|   41414141|    '234567'|'Consectetur adip...|      22|03-2027|        57|'company 15'|    0|\n",
      "|   44444444|    '012345'|'Quis nostrud exe...|      23|05-2025|       105|'company 18'|    1|\n",
      "|   45645645|    'qwerty'|'Lorem ipsum dolo...|      30|06-2025|        89| 'company 2'|    1|\n",
      "|   46464646|    '234567'|'Excepteur sint o...|      36|10-2026|        62|'company 20'|    1|\n",
      "|   47474747|    '890123'|'Sunt in culpa qu...|      25|02-2025|       120| 'company 1'|    1|\n",
      "|   48484848|    '456789'|'Lorem ipsum dolo...|      31|12-2026|        85| 'company 2'|    1|\n",
      "|   49494949|    '012345'|'Consectetur adip...|      34|07-2027|        60| 'company 3'|    0|\n",
      "|   78978978|    'foobar'|'Consectetur adip...|      25|09-2027|        55| 'company 3'|    0|\n",
      "+-----------+------------+--------------------+--------+-------+----------+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "integrated_df = spark.read.option('header', True).csv(\"./bom_sources/source_1.csv\")\n",
    "integrated_df.show()\n",
    "# # Handling Missing Values\n",
    "# # Count missing values in each column\n",
    "missing_counts_for_each_col = integrated_df.select([count(when(isnan(c) |  col(c).isNull(), 1)).alias(c) for c in integrated_df.columns])\n",
    "missing_counts_for_each_col.show(200)\n",
    "\n",
    "\n",
    "# # Removing Duplicate Entries\n",
    "# # Drop duplicate rows based on selected columns\n",
    "cleaned_df = integrated_df.dropDuplicates(['Part_Number'])\n",
    "\n",
    "\n",
    "# # Validating Quantity Values\n",
    "# # Check for out-of-range quantity values\n",
    "valid_quantity_df = cleaned_df.filter((col(\"Quantity\") >= 20) & (col(\"Quantity\") <= 40))\n",
    "valid_quantity_df.show(50)\n",
    "\n",
    "# # Verifying Part Numbers\n",
    "# # Validate part numbers based on predefined patterns\n",
    "valid_part_numbers_df = valid_quantity_df.filter(col(\"Part_Number\").rlike(\"[0-9]{3}\"))\n",
    "valid_part_numbers_df.show(50)\n",
    "\n",
    "# # Cross-Referencing with Reference Data (Example: Supplier Information)\n",
    "# # Join with reference data to validate supplier information\n",
    "# reference_supplier_df = spark.read.parquet(\"supplier_data.parquet\")\n",
    "# validated_bom_df = valid_part_numbers_df.join(reference_supplier_df, \"Component_ID\", \"left_outer\")\n",
    "\n",
    "# # Checking Hierarchical Relationships (Example: Assembly Quantity Check)\n",
    "# # Validate assembly quantities against sum of sub-component quantities\n",
    "# assembly_quantity_check_df = validated_bom_df.withColumn(\"Quantity_Check\", when(\n",
    "#     col(\"Component_Type\") == \"Assembly\", col(\"Quantity\") == col(\"Subcomponent_Quantities\").sum()).otherwise(True))\n",
    "\n",
    "# # Write the cleaned and validated data to a new Parquet file\n",
    "# assembly_quantity_check_df.write.parquet(\"cleaned_validated_bom.parquet\")\n",
    "\n",
    "# # Stop the Spark session\n",
    "# spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482a0eba-18e1-45b0-93f6-df1c99365137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833c6f9e-6a52-4b02-9107-e025d94a522b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c670000-523f-4105-b49c-7df8678369b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# titanic_1.fillna(value='GG', subset='cabin').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
