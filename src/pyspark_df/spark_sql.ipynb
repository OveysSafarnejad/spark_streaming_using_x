{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbec3be9-68de-46c4-bfda-2dbfb23b1ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import findspark\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType, MapType, DateType\n",
    "from pyspark.sql.functions import col, lit, explode, split , array, array_contains, \\\n",
    "    udf, map_values, when, count, min, max, avg, row_number, rank, dense_rank, percent_rank, \\\n",
    "    lead, lag, first, last, nth_value, from_json, map_keys, to_json, json_tuple\n",
    "\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bfcaee4-5c07-4daa-87b9-277656eacd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/04 13:54:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Spark SQL').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7807ab0-c315-4a95-8dd7-8e7691aa1fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_df = spark.createDataFrame(\n",
    "    data=[(1,'ali'),(2, 'akram'),(3, 'oveys'),(4, 'ala'),(5, 'omid'),(6, 'mobin')], schema=['id', 'name']\n",
    ")\n",
    "\n",
    "right_df = spark.createDataFrame(\n",
    "        data=[(8,'mehdi'),(9, 'simin'),(3, 'oveys'),(4, 'ala'),(10, 'aida')], schema=['id', 'name']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50c93334-c356-466c-824e-d130930aa949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+\n",
      "| id| name| name|\n",
      "+---+-----+-----+\n",
      "|  1|  ali| NULL|\n",
      "|  2|akram| NULL|\n",
      "|  3|oveys|oveys|\n",
      "|  4|  ala|  ala|\n",
      "|  5| omid| NULL|\n",
      "|  6|mobin| NULL|\n",
      "+---+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# options are inner, outer, left, right\n",
    "left_df.join(right_df, on=['id'], how='left').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf6b2181-59b8-424b-856e-e5a952d35331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|name|\n",
      "+---+----+\n",
      "|  1|   a|\n",
      "|  2|   b|\n",
      "|  1|   d|\n",
      "|  3|   b|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True)\n",
    "])\n",
    "\n",
    "rdd1 = spark.sparkContext.parallelize([(1,'a'),(2, 'b')])\n",
    "rdd2 = spark.sparkContext.parallelize([(1,'d'),(3, 'b')])\n",
    "rdd_res = rdd1.union(rdd2)\n",
    "\n",
    "spark.createDataFrame(rdd_res, schema).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2f7b557-fc8d-4404-ba7a-7a634dc5fcb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+\n",
      "|pid|survived|class|                name|   sex| age|sib|parch|          tikcet|   fare|cabin|embarked|\n",
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+\n",
      "|  1|       0|    3|Braund, Mr. Owen ...|  male|  22|  1|    0|       A/5 21171|   7.25| NULL|       S|\n",
      "|  2|       1|    1|Cumings, Mrs. Joh...|female|  38|  1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|  3|       1|    3|Heikkinen, Miss. ...|female|  26|  0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
      "|  4|       1|    1|Futrelle, Mrs. Ja...|female|  35|  1|    0|          113803|   53.1| C123|       S|\n",
      "|  5|       0|    3|Allen, Mr. Willia...|  male|  35|  0|    0|          373450|   8.05| NULL|       S|\n",
      "|  6|       0|    3|    Moran, Mr. James|  male|NULL|  0|    0|          330877| 8.4583| NULL|       Q|\n",
      "|  7|       0|    1|McCarthy, Mr. Tim...|  male|  54|  0|    0|           17463|51.8625|  E46|       S|\n",
      "|  8|       0|    3|Palsson, Master. ...|  male|   2|  3|    1|          349909| 21.075| NULL|       S|\n",
      "|  9|       1|    3|Johnson, Mrs. Osc...|female|  27|  0|    2|          347742|11.1333| NULL|       S|\n",
      "| 10|       1|    2|Nasser, Mrs. Nich...|female|  14|  1|    0|          237736|30.0708| NULL|       C|\n",
      "| 11|       1|    3|Sandstrom, Miss. ...|female|   4|  1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "| 12|       1|    1|Bonnell, Miss. El...|female|  58|  0|    0|          113783|  26.55| C103|       S|\n",
      "| 13|       0|    3|Saundercock, Mr. ...|  male|  20|  0|    0|       A/5. 2151|   8.05| NULL|       S|\n",
      "| 14|       0|    3|Andersson, Mr. An...|  male|  39|  1|    5|          347082| 31.275| NULL|       S|\n",
      "| 15|       0|    3|Vestrom, Miss. Hu...|female|  14|  0|    0|          350406| 7.8542| NULL|       S|\n",
      "| 16|       1|    2|Hewlett, Mrs. (Ma...|female|  55|  0|    0|          248706|   16.0| NULL|       S|\n",
      "| 17|       0|    3|Rice, Master. Eugene|  male|   2|  4|    1|          382652| 29.125| NULL|       Q|\n",
      "| 18|       1|    2|Williams, Mr. Cha...|  male|NULL|  0|    0|          244373|   13.0| NULL|       S|\n",
      "| 19|       0|    3|Vander Planke, Mr...|female|  31|  1|    0|          345763|   18.0| NULL|       S|\n",
      "| 20|       1|    3|Masselmani, Mrs. ...|female|NULL|  0|    0|            2649|  7.225| NULL|       C|\n",
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/27 09:29:13 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked\n",
      " Schema: pid, survived, class, name, sex, age, sib, parch, tikcet, fare, cabin, embarked\n",
      "Expected: pid but found: PassengerId\n",
      "CSV file: file:///Users/hso/Documents/WORKSPACE/LEARNING/spark_streaming_using_x/src/titanic.csv\n"
     ]
    }
   ],
   "source": [
    "titanic_shcema = StructType()\\\n",
    "    .add('pid', 'integer') \\\n",
    "    .add('survived', 'integer') \\\n",
    "    .add('class', 'integer') \\\n",
    "    .add('name', 'string') \\\n",
    "    .add('sex', 'string') \\\n",
    "    .add('age', 'integer') \\\n",
    "    .add('sib', 'integer') \\\n",
    "    .add('parch', 'integer') \\\n",
    "    .add('tikcet', 'string') \\\n",
    "    .add('fare', 'float') \\\n",
    "    .add('cabin', 'string') \\\n",
    "    .add('embarked', 'string') \\\n",
    "\n",
    "\n",
    "\n",
    "titanic_df = spark.read.option('header', 'true').schema(titanic_shcema).csv('titanic.csv')\n",
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0a70fb5-dda5-4210-b446-fe581c41b2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+\n",
      "|pid|survived|class|                name|   sex| age|sib|parch|          tikcet|   fare|cabin|embarked|\n",
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+\n",
      "|  1|       0|    3|Braund, Mr. Owen ...|  male|  22|  1|    0|       A/5 21171|   7.25| NULL|       S|\n",
      "|  2|       1|    1|Cumings, Mrs. Joh...|female|  38|  1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|  3|       1|    3|Heikkinen, Miss. ...|female|  26|  0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
      "|  4|       1|    1|Futrelle, Mrs. Ja...|female|  35|  1|    0|          113803|   53.1| C123|       S|\n",
      "|  5|       0|    3|Allen, Mr. Willia...|  male|  35|  0|    0|          373450|   8.05| NULL|       S|\n",
      "|  6|       0|    3|    Moran, Mr. James|  male|NULL|  0|    0|          330877| 8.4583| NULL|       Q|\n",
      "|  7|       0|    1|McCarthy, Mr. Tim...|  male|  54|  0|    0|           17463|51.8625|  E46|       S|\n",
      "|  8|       0|    3|Palsson, Master. ...|  male|   2|  3|    1|          349909| 21.075| NULL|       S|\n",
      "|  9|       1|    3|Johnson, Mrs. Osc...|female|  27|  0|    2|          347742|11.1333| NULL|       S|\n",
      "| 10|       1|    2|Nasser, Mrs. Nich...|female|  14|  1|    0|          237736|30.0708| NULL|       C|\n",
      "| 11|       1|    3|Sandstrom, Miss. ...|female|   4|  1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "| 12|       1|    1|Bonnell, Miss. El...|female|  58|  0|    0|          113783|  26.55| C103|       S|\n",
      "| 13|       0|    3|Saundercock, Mr. ...|  male|  20|  0|    0|       A/5. 2151|   8.05| NULL|       S|\n",
      "| 14|       0|    3|Andersson, Mr. An...|  male|  39|  1|    5|          347082| 31.275| NULL|       S|\n",
      "| 15|       0|    3|Vestrom, Miss. Hu...|female|  14|  0|    0|          350406| 7.8542| NULL|       S|\n",
      "| 16|       1|    2|Hewlett, Mrs. (Ma...|female|  55|  0|    0|          248706|   16.0| NULL|       S|\n",
      "| 17|       0|    3|Rice, Master. Eugene|  male|   2|  4|    1|          382652| 29.125| NULL|       Q|\n",
      "| 18|       1|    2|Williams, Mr. Cha...|  male|NULL|  0|    0|          244373|   13.0| NULL|       S|\n",
      "| 19|       0|    3|Vander Planke, Mr...|female|  31|  1|    0|          345763|   18.0| NULL|       S|\n",
      "| 20|       1|    3|Masselmani, Mrs. ...|female|NULL|  0|    0|            2649|  7.225| NULL|       C|\n",
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/27 09:29:13 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked\n",
      " Schema: pid, survived, class, name, sex, age, sib, parch, tikcet, fare, cabin, embarked\n",
      "Expected: pid but found: PassengerId\n",
      "CSV file: file:///Users/hso/Documents/WORKSPACE/LEARNING/spark_streaming_using_x/src/titanic.csv\n"
     ]
    }
   ],
   "source": [
    "titanic_1 = titanic_df.alias('titanic_1')\n",
    "\n",
    "titanic_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73a4f74f-8e56-46d7-8f68-438d508401f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|cabin|\n",
      "+-----+\n",
      "| NULL|\n",
      "|  C85|\n",
      "| NULL|\n",
      "| C123|\n",
      "| NULL|\n",
      "| NULL|\n",
      "|  E46|\n",
      "| NULL|\n",
      "| NULL|\n",
      "| NULL|\n",
      "|   G6|\n",
      "| C103|\n",
      "| NULL|\n",
      "| NULL|\n",
      "| NULL|\n",
      "| NULL|\n",
      "| NULL|\n",
      "| NULL|\n",
      "| NULL|\n",
      "| NULL|\n",
      "+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_1.select('cabin').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfc1dede-45ff-412e-a373-3f87536a32e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_1.filter(titanic_1.age > 35).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40bbb422-042b-42e9-b1be-d3da4d46fb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+--------+\n",
      "|                name| age|survived|\n",
      "+--------------------+----+--------+\n",
      "|Braund, Mr. Owen ...|  22|       0|\n",
      "|Allen, Mr. Willia...|  35|       0|\n",
      "|    Moran, Mr. James|NULL|       0|\n",
      "|McCarthy, Mr. Tim...|  54|       0|\n",
      "|Palsson, Master. ...|   2|       0|\n",
      "|Saundercock, Mr. ...|  20|       0|\n",
      "|Andersson, Mr. An...|  39|       0|\n",
      "|Vestrom, Miss. Hu...|  14|       0|\n",
      "|Rice, Master. Eugene|   2|       0|\n",
      "|Vander Planke, Mr...|  31|       0|\n",
      "|Fynney, Mr. Joseph J|  35|       0|\n",
      "|Palsson, Miss. To...|   8|       0|\n",
      "|Emir, Mr. Farred ...|NULL|       0|\n",
      "|Fortune, Mr. Char...|  19|       0|\n",
      "| Todoroff, Mr. Lalio|NULL|       0|\n",
      "|Uruchurtu, Don. M...|  40|       0|\n",
      "|Wheadon, Mr. Edwa...|  66|       0|\n",
      "|Meyer, Mr. Edgar ...|  28|       0|\n",
      "|Holverson, Mr. Al...|  42|       0|\n",
      "|Cann, Mr. Ernest ...|  21|       0|\n",
      "+--------------------+----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_1.select('name', 'age', 'survived').filter('survived = 0').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4429e21-bf2a-4c3f-a0de-214a6197f1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|                name|survived|\n",
      "+--------------------+--------+\n",
      "|Heikkinen, Miss. ...|       1|\n",
      "|Johnson, Mrs. Osc...|       1|\n",
      "|Nasser, Mrs. Nich...|       1|\n",
      "|Sandstrom, Miss. ...|       1|\n",
      "|\"McGowan, Miss. A...|       1|\n",
      "|Sloper, Mr. Willi...|       1|\n",
      "|Nicola-Yarred, Mi...|       1|\n",
      "|Laroche, Miss. Si...|       1|\n",
      "|Devaney, Miss. Ma...|       1|\n",
      "|Faunthorpe, Mrs. ...|       1|\n",
      "|   Rugg, Miss. Emily|       1|\n",
      "|West, Miss. Const...|       1|\n",
      "|Nye, Mrs. (Elizab...|       1|\n",
      "|Andersson, Miss. ...|       1|\n",
      "|Sheerlinck, Mr. J...|       1|\n",
      "| Ilett, Miss. Bertha|       1|\n",
      "|Fortune, Miss. Ma...|       1|\n",
      "|Greenfield, Mr. W...|       1|\n",
      "|Salkjelsvik, Miss...|       1|\n",
      "|Nicola-Yarred, Ma...|       1|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_1.select('name', 'survived').where('age < 30 and survived=1').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e63c8da0-5bec-4204-b3ae-6958956688ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+--------------------+------+---+---+-----+-----------+-------+-----------+--------+\n",
      "|pid|survived|class|                name|   sex|age|sib|parch|     tikcet|   fare|      cabin|embarked|\n",
      "+---+--------+-----+--------------------+------+---+---+-----+-----------+-------+-----------+--------+\n",
      "|631|       1|    1|Barkworth, Mr. Al...|  male| 80|  0|    0|      27042|   30.0|        A23|       S|\n",
      "|852|       0|    3| Svensson, Mr. Johan|  male| 74|  0|    0|     347060|  7.775|       NULL|       S|\n",
      "|494|       0|    1|Artagaveytia, Mr....|  male| 71|  0|    0|   PC 17609|49.5042|       NULL|       C|\n",
      "| 97|       0|    1|Goldschmidt, Mr. ...|  male| 71|  0|    0|   PC 17754|34.6542|         A5|       C|\n",
      "|746|       0|    1|Crosby, Capt. Edw...|  male| 70|  1|    1|  WE/P 5735|   71.0|        B22|       S|\n",
      "|673|       0|    2|Mitchell, Mr. Hen...|  male| 70|  0|    0| C.A. 24580|   10.5|       NULL|       S|\n",
      "| 34|       0|    2|Wheadon, Mr. Edwa...|  male| 66|  0|    0| C.A. 24579|   10.5|       NULL|       S|\n",
      "|281|       0|    3|    Duane, Mr. Frank|  male| 65|  0|    0|     336439|   7.75|       NULL|       Q|\n",
      "|457|       0|    1|Millet, Mr. Franc...|  male| 65|  0|    0|      13509|  26.55|        E38|       S|\n",
      "| 55|       0|    1|Ostby, Mr. Engelh...|  male| 65|  0|    1|     113509|61.9792|        B30|       C|\n",
      "|439|       0|    1|   Fortune, Mr. Mark|  male| 64|  1|    4|      19950|  263.0|C23 C25 C27|       S|\n",
      "|546|       0|    1|Nicholson, Mr. Ar...|  male| 64|  0|    0|        693|   26.0|       NULL|       S|\n",
      "|276|       1|    1|Andrews, Miss. Ko...|female| 63|  1|    0|      13502|77.9583|         D7|       S|\n",
      "|484|       1|    3|Turkula, Mrs. (He...|female| 63|  0|    0|       4134| 9.5875|       NULL|       S|\n",
      "|571|       1|    2|  Harris, Mr. George|  male| 62|  0|    0|S.W./PP 752|   10.5|       NULL|       S|\n",
      "|253|       0|    1|Stead, Mr. Willia...|  male| 62|  0|    0|     113514|  26.55|        C87|       S|\n",
      "|830|       1|    1|Stone, Mrs. Georg...|female| 62|  0|    0|     113572|   80.0|        B28|    NULL|\n",
      "|556|       0|    1|  Wright, Mr. George|  male| 62|  0|    0|     113807|  26.55|       NULL|       S|\n",
      "|327|       0|    3|Nysveen, Mr. Joha...|  male| 61|  0|    0|     345364| 6.2375|       NULL|       S|\n",
      "|626|       0|    1|Sutton, Mr. Frede...|  male| 61|  0|    0|      36963|32.3208|        D50|       S|\n",
      "+---+--------+-----+--------------------+------+---+---+-----+-----------+-------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/27 09:29:15 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked\n",
      " Schema: pid, survived, class, name, sex, age, sib, parch, tikcet, fare, cabin, embarked\n",
      "Expected: pid but found: PassengerId\n",
      "CSV file: file:///Users/hso/Documents/WORKSPACE/LEARNING/spark_streaming_using_x/src/titanic.csv\n"
     ]
    }
   ],
   "source": [
    "titanic_1.sort(['age', 'name'], ascending=[False, True]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff0714a5-adde-4a4a-8ce4-0db14cf69e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/27 09:29:15 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "24/03/27 09:29:15 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked\n",
      " Schema: pid, survived, class, name, sex, age, sib, parch, tikcet, fare, cabin, embarked\n",
      "Expected: pid but found: PassengerId\n",
      "CSV file: file:///Users/hso/Documents/WORKSPACE/LEARNING/spark_streaming_using_x/src/titanic.csv\n",
      "[Stage 18:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "|summary|              pid|           survived|             class|                name|   sex|               age|               sib|              parch|            tikcet|             fare|cabin|embarked|\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "|  count|              891|                891|               891|                 891|   891|               689|               891|                891|               891|              891|  204|     889|\n",
      "|   mean|            446.0| 0.3838383838383838| 2.308641975308642|                NULL|  NULL|29.847605224963715|0.5230078563411896|0.38159371492704824|260318.54916792738|32.20420804114722| NULL|    NULL|\n",
      "| stddev|257.3538420152301|0.48659245426485753|0.8360712409770491|                NULL|  NULL|14.317668714749662|1.1027434322934315| 0.8060572211299488|471609.26868834975|49.69342916316158| NULL|    NULL|\n",
      "|    min|                1|                  0|                 1|\"Andersson, Mr. A...|female|                 1|                 0|                  0|            110152|              0.0|  A10|       C|\n",
      "|    max|              891|                  1|                 3|van Melkebeke, Mr...|  male|                80|                 8|                  6|         WE/P 5735|         512.3292|    T|       S|\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "titanic_1.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbef9dc9-5457-4fa2-9e07-4fa2c924bf4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pid',\n",
       " 'survived',\n",
       " 'class',\n",
       " 'name',\n",
       " 'sex',\n",
       " 'age',\n",
       " 'sib',\n",
       " 'parch',\n",
       " 'tikcet',\n",
       " 'fare',\n",
       " 'cabin',\n",
       " 'embarked']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4b01f69-f585-4e7c-ac71-d45ecfedcec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pid: integer (nullable = true)\n",
      " |-- survived: integer (nullable = true)\n",
      " |-- class: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sib: integer (nullable = true)\n",
      " |-- parch: integer (nullable = true)\n",
      " |-- tikcet: string (nullable = true)\n",
      " |-- fare: float (nullable = true)\n",
      " |-- cabin: string (nullable = true)\n",
      " |-- embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e020cdf-b30b-4503-9922-b83898bc79b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method withColumn in module pyspark.sql.dataframe:\n",
      "\n",
      "withColumn(colName: str, col: pyspark.sql.column.Column) -> 'DataFrame' method of pyspark.sql.dataframe.DataFrame instance\n",
      "    Returns a new :class:`DataFrame` by adding a column or replacing the\n",
      "    existing column that has the same name.\n",
      "    \n",
      "    The column expression must be an expression over this :class:`DataFrame`; attempting to add\n",
      "    a column from some other :class:`DataFrame` will raise an error.\n",
      "    \n",
      "    .. versionadded:: 1.3.0\n",
      "    \n",
      "    .. versionchanged:: 3.4.0\n",
      "        Supports Spark Connect.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    colName : str\n",
      "        string, name of the new column.\n",
      "    col : :class:`Column`\n",
      "        a :class:`Column` expression for the new column.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    :class:`DataFrame`\n",
      "        DataFrame with new or replaced column.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    This method introduces a projection internally. Therefore, calling it multiple\n",
      "    times, for instance, via loops in order to add multiple columns can generate big\n",
      "    plans which can cause performance issues and even `StackOverflowException`.\n",
      "    To avoid this, use :func:`select` with multiple columns at once.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = spark.createDataFrame([(2, \"Alice\"), (5, \"Bob\")], schema=[\"age\", \"name\"])\n",
      "    >>> df.withColumn('age2', df.age + 2).show()\n",
      "    +---+-----+----+\n",
      "    |age| name|age2|\n",
      "    +---+-----+----+\n",
      "    |  2|Alice|   4|\n",
      "    |  5|  Bob|   7|\n",
      "    +---+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(titanic_1.withColumn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46baea75-1630-4b11-976e-65aa39ee1d3d",
   "metadata": {},
   "source": [
    "# withColumn()\n",
    "\n",
    "##### It's a transformation operation which is used for \n",
    "##### 1. adding a new column\n",
    "##### 2. changing the dtype of an existing column\n",
    "##### 3. changing the value of an existing column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a00d9a5c-6198-4226-a7e5-51c4c8a6f06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+\n",
      "|pid|survived|class|                name|   sex| age|sib|parch|          tikcet|   fare|cabin|embarked|\n",
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+\n",
      "|  1|       0|    3|Braund, Mr. Owen ...|  male|  22|1.0|    0|       A/5 21171|   7.25| NULL|       S|\n",
      "|  2|       1|    1|Cumings, Mrs. Joh...|female|  38|1.0|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|  3|       1|    3|Heikkinen, Miss. ...|female|  26|0.0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
      "|  4|       1|    1|Futrelle, Mrs. Ja...|female|  35|1.0|    0|          113803|   53.1| C123|       S|\n",
      "|  5|       0|    3|Allen, Mr. Willia...|  male|  35|0.0|    0|          373450|   8.05| NULL|       S|\n",
      "|  6|       0|    3|    Moran, Mr. James|  male|NULL|0.0|    0|          330877| 8.4583| NULL|       Q|\n",
      "|  7|       0|    1|McCarthy, Mr. Tim...|  male|  54|0.0|    0|           17463|51.8625|  E46|       S|\n",
      "|  8|       0|    3|Palsson, Master. ...|  male|   2|3.0|    1|          349909| 21.075| NULL|       S|\n",
      "|  9|       1|    3|Johnson, Mrs. Osc...|female|  27|0.0|    2|          347742|11.1333| NULL|       S|\n",
      "| 10|       1|    2|Nasser, Mrs. Nich...|female|  14|1.0|    0|          237736|30.0708| NULL|       C|\n",
      "| 11|       1|    3|Sandstrom, Miss. ...|female|   4|1.0|    1|         PP 9549|   16.7|   G6|       S|\n",
      "| 12|       1|    1|Bonnell, Miss. El...|female|  58|0.0|    0|          113783|  26.55| C103|       S|\n",
      "| 13|       0|    3|Saundercock, Mr. ...|  male|  20|0.0|    0|       A/5. 2151|   8.05| NULL|       S|\n",
      "| 14|       0|    3|Andersson, Mr. An...|  male|  39|1.0|    5|          347082| 31.275| NULL|       S|\n",
      "| 15|       0|    3|Vestrom, Miss. Hu...|female|  14|0.0|    0|          350406| 7.8542| NULL|       S|\n",
      "| 16|       1|    2|Hewlett, Mrs. (Ma...|female|  55|0.0|    0|          248706|   16.0| NULL|       S|\n",
      "| 17|       0|    3|Rice, Master. Eugene|  male|   2|4.0|    1|          382652| 29.125| NULL|       Q|\n",
      "| 18|       1|    2|Williams, Mr. Cha...|  male|NULL|0.0|    0|          244373|   13.0| NULL|       S|\n",
      "| 19|       0|    3|Vander Planke, Mr...|female|  31|1.0|    0|          345763|   18.0| NULL|       S|\n",
      "| 20|       1|    3|Masselmani, Mrs. ...|female|NULL|0.0|    0|            2649|  7.225| NULL|       C|\n",
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/27 09:45:24 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked\n",
      " Schema: pid, survived, class, name, sex, age, sib, parch, tikcet, fare, cabin, embarked\n",
      "Expected: pid but found: PassengerId\n",
      "CSV file: file:///Users/hso/Documents/WORKSPACE/LEARNING/spark_streaming_using_x/src/titanic.csv\n"
     ]
    }
   ],
   "source": [
    "# change dtype\n",
    "titanic_1.withColumn(colName='sib', col=titanic_1.sib.cast('float')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fcc70812-1344-4ee8-ac04-6abdb019c43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+\n",
      "|pid|survived|class|                name|   sex| age|sib|parch|          tikcet|   fare|cabin|embarked|\n",
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+\n",
      "|  1|       0|    3|Braund, Mr. Owen ...|  male|  22|  1|    0|       A/5 21171|   7.25| NULL|       S|\n",
      "|  2|       1|    1|Cumings, Mrs. Joh...|female|  38|  1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|  3|       1|    3|Heikkinen, Miss. ...|female|  26|  0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
      "|  4|       1|    1|Futrelle, Mrs. Ja...|female|  35|  1|    0|          113803|   53.1| C123|       S|\n",
      "|  5|       0|    3|Allen, Mr. Willia...|  male|  35|  0|    0|          373450|   8.05| NULL|       S|\n",
      "|  6|       0|    3|    Moran, Mr. James|  male|NULL|  0|    0|          330877| 8.4583| NULL|       Q|\n",
      "|  7|       0|    1|McCarthy, Mr. Tim...|  male|  54|  0|    0|           17463|51.8625|  E46|       S|\n",
      "|  8|       0|    3|Palsson, Master. ...|  male|   2|  3|    1|          349909| 21.075| NULL|       S|\n",
      "|  9|       1|    3|Johnson, Mrs. Osc...|female|  27|  0|    2|          347742|11.1333| NULL|       S|\n",
      "| 10|       1|    2|Nasser, Mrs. Nich...|female|  14|  1|    0|          237736|30.0708| NULL|       C|\n",
      "| 11|       1|    3|Sandstrom, Miss. ...|female|   4|  1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "| 12|       1|    1|Bonnell, Miss. El...|female|  58|  0|    0|          113783|  26.55| C103|       S|\n",
      "| 13|       0|    3|Saundercock, Mr. ...|  male|  20|  0|    0|       A/5. 2151|   8.05| NULL|       S|\n",
      "| 14|       0|    3|Andersson, Mr. An...|  male|  39|  1|    5|          347082| 31.275| NULL|       S|\n",
      "| 15|       0|    3|Vestrom, Miss. Hu...|female|  14|  0|    0|          350406| 7.8542| NULL|       S|\n",
      "| 16|       1|    2|Hewlett, Mrs. (Ma...|female|  55|  0|    0|          248706|   16.0| NULL|       S|\n",
      "| 17|       0|    3|Rice, Master. Eugene|  male|   2|  4|    1|          382652| 29.125| NULL|       Q|\n",
      "| 18|       1|    2|Williams, Mr. Cha...|  male|NULL|  0|    0|          244373|   13.0| NULL|       S|\n",
      "| 19|       0|    3|Vander Planke, Mr...|female|  31|  1|    0|          345763|   18.0| NULL|       S|\n",
      "| 20|       1|    3|Masselmani, Mrs. ...|female|NULL|  0|    0|            2649|  7.225| NULL|       C|\n",
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/27 09:45:34 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked\n",
      " Schema: pid, survived, class, name, sex, age, sib, parch, tikcet, fare, cabin, embarked\n",
      "Expected: pid but found: PassengerId\n",
      "CSV file: file:///Users/hso/Documents/WORKSPACE/LEARNING/spark_streaming_using_x/src/titanic.csv\n"
     ]
    }
   ],
   "source": [
    "# data manipulation\n",
    "titanic_1.withColumn('sib', titanic_1.sib * 1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5eb6f0a9-2e3f-430c-96c6-2f565409663f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+-----------+\n",
      "|pid|survived|class|                name|   sex| age|sib|parch|          tikcet|   fare|cabin|embarked|nationality|\n",
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+-----------+\n",
      "|  1|       0|    3|Braund, Mr. Owen ...|  male|  22|  1|    0|       A/5 21171|   7.25| NULL|       S|        XYZ|\n",
      "|  2|       1|    1|Cumings, Mrs. Joh...|female|  38|  1|    0|        PC 17599|71.2833|  C85|       C|        XYZ|\n",
      "|  3|       1|    3|Heikkinen, Miss. ...|female|  26|  0|    0|STON/O2. 3101282|  7.925| NULL|       S|        XYZ|\n",
      "|  4|       1|    1|Futrelle, Mrs. Ja...|female|  35|  1|    0|          113803|   53.1| C123|       S|        XYZ|\n",
      "|  5|       0|    3|Allen, Mr. Willia...|  male|  35|  0|    0|          373450|   8.05| NULL|       S|        XYZ|\n",
      "|  6|       0|    3|    Moran, Mr. James|  male|NULL|  0|    0|          330877| 8.4583| NULL|       Q|        XYZ|\n",
      "|  7|       0|    1|McCarthy, Mr. Tim...|  male|  54|  0|    0|           17463|51.8625|  E46|       S|        XYZ|\n",
      "|  8|       0|    3|Palsson, Master. ...|  male|   2|  3|    1|          349909| 21.075| NULL|       S|        XYZ|\n",
      "|  9|       1|    3|Johnson, Mrs. Osc...|female|  27|  0|    2|          347742|11.1333| NULL|       S|        XYZ|\n",
      "| 10|       1|    2|Nasser, Mrs. Nich...|female|  14|  1|    0|          237736|30.0708| NULL|       C|        XYZ|\n",
      "| 11|       1|    3|Sandstrom, Miss. ...|female|   4|  1|    1|         PP 9549|   16.7|   G6|       S|        XYZ|\n",
      "| 12|       1|    1|Bonnell, Miss. El...|female|  58|  0|    0|          113783|  26.55| C103|       S|        XYZ|\n",
      "| 13|       0|    3|Saundercock, Mr. ...|  male|  20|  0|    0|       A/5. 2151|   8.05| NULL|       S|        XYZ|\n",
      "| 14|       0|    3|Andersson, Mr. An...|  male|  39|  1|    5|          347082| 31.275| NULL|       S|        XYZ|\n",
      "| 15|       0|    3|Vestrom, Miss. Hu...|female|  14|  0|    0|          350406| 7.8542| NULL|       S|        XYZ|\n",
      "| 16|       1|    2|Hewlett, Mrs. (Ma...|female|  55|  0|    0|          248706|   16.0| NULL|       S|        XYZ|\n",
      "| 17|       0|    3|Rice, Master. Eugene|  male|   2|  4|    1|          382652| 29.125| NULL|       Q|        XYZ|\n",
      "| 18|       1|    2|Williams, Mr. Cha...|  male|NULL|  0|    0|          244373|   13.0| NULL|       S|        XYZ|\n",
      "| 19|       0|    3|Vander Planke, Mr...|female|  31|  1|    0|          345763|   18.0| NULL|       S|        XYZ|\n",
      "| 20|       1|    3|Masselmani, Mrs. ...|female|NULL|  0|    0|            2649|  7.225| NULL|       C|        XYZ|\n",
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/27 09:45:44 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked\n",
      " Schema: pid, survived, class, name, sex, age, sib, parch, tikcet, fare, cabin, embarked\n",
      "Expected: pid but found: PassengerId\n",
      "CSV file: file:///Users/hso/Documents/WORKSPACE/LEARNING/spark_streaming_using_x/src/titanic.csv\n"
     ]
    }
   ],
   "source": [
    "# creating new col\n",
    "titanic_1.withColumn(colName='nationality', col=lit('XYZ')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf79114-2f85-4211-8c50-68120c01b85e",
   "metadata": {},
   "source": [
    "# withColumnRename()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c86e28c-6a4e-4fff-a0cb-2b448920dd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+\n",
      "|pid|survived|class|                name|   sex| age|sib|parch|             pnr|   fare|cabin|embarked|\n",
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+\n",
      "|  1|       0|    3|Braund, Mr. Owen ...|  male|  22|  1|    0|       A/5 21171|   7.25| NULL|       S|\n",
      "|  2|       1|    1|Cumings, Mrs. Joh...|female|  38|  1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|  3|       1|    3|Heikkinen, Miss. ...|female|  26|  0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
      "|  4|       1|    1|Futrelle, Mrs. Ja...|female|  35|  1|    0|          113803|   53.1| C123|       S|\n",
      "|  5|       0|    3|Allen, Mr. Willia...|  male|  35|  0|    0|          373450|   8.05| NULL|       S|\n",
      "|  6|       0|    3|    Moran, Mr. James|  male|NULL|  0|    0|          330877| 8.4583| NULL|       Q|\n",
      "|  7|       0|    1|McCarthy, Mr. Tim...|  male|  54|  0|    0|           17463|51.8625|  E46|       S|\n",
      "|  8|       0|    3|Palsson, Master. ...|  male|   2|  3|    1|          349909| 21.075| NULL|       S|\n",
      "|  9|       1|    3|Johnson, Mrs. Osc...|female|  27|  0|    2|          347742|11.1333| NULL|       S|\n",
      "| 10|       1|    2|Nasser, Mrs. Nich...|female|  14|  1|    0|          237736|30.0708| NULL|       C|\n",
      "| 11|       1|    3|Sandstrom, Miss. ...|female|   4|  1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "| 12|       1|    1|Bonnell, Miss. El...|female|  58|  0|    0|          113783|  26.55| C103|       S|\n",
      "| 13|       0|    3|Saundercock, Mr. ...|  male|  20|  0|    0|       A/5. 2151|   8.05| NULL|       S|\n",
      "| 14|       0|    3|Andersson, Mr. An...|  male|  39|  1|    5|          347082| 31.275| NULL|       S|\n",
      "| 15|       0|    3|Vestrom, Miss. Hu...|female|  14|  0|    0|          350406| 7.8542| NULL|       S|\n",
      "| 16|       1|    2|Hewlett, Mrs. (Ma...|female|  55|  0|    0|          248706|   16.0| NULL|       S|\n",
      "| 17|       0|    3|Rice, Master. Eugene|  male|   2|  4|    1|          382652| 29.125| NULL|       Q|\n",
      "| 18|       1|    2|Williams, Mr. Cha...|  male|NULL|  0|    0|          244373|   13.0| NULL|       S|\n",
      "| 19|       0|    3|Vander Planke, Mr...|female|  31|  1|    0|          345763|   18.0| NULL|       S|\n",
      "| 20|       1|    3|Masselmani, Mrs. ...|female|NULL|  0|    0|            2649|  7.225| NULL|       C|\n",
      "+---+--------+-----+--------------------+------+----+---+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/27 09:50:25 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked\n",
      " Schema: pid, survived, class, name, sex, age, sib, parch, tikcet, fare, cabin, embarked\n",
      "Expected: pid but found: PassengerId\n",
      "CSV file: file:///Users/hso/Documents/WORKSPACE/LEARNING/spark_streaming_using_x/src/titanic.csv\n"
     ]
    }
   ],
   "source": [
    "titanic_1.withColumnRenamed(existing='tikcet', new='pnr').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1d161e-4da2-44be-b18d-e899bd11eaa8",
   "metadata": {},
   "source": [
    "# explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3014e335-e408-428f-81a5-c76d58cc91da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------------+\n",
      "| id|    name|              skills|\n",
      "+---+--------+--------------------+\n",
      "|  1|   Oveys|      [java, python]|\n",
      "|  2|Mohammad|[Java, Python, Do...|\n",
      "|  3|     Ala|[ObjectiveC, Swif...|\n",
      "+---+--------+--------------------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- skills: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Oveys', ['java', 'python']), (2, 'Mohammad', ['Java', 'Python', 'Docker']), (3, 'Ala',['ObjectiveC', 'Swift', 'swiftUI', 'iOS'])]\n",
    "devs = spark.createDataFrame(data, ['id', 'name', 'skills'])\n",
    "devs.show()\n",
    "devs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b509f2b0-d66f-4b54-acfb-99ddd6a181a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+\n",
      "| id|    name|    skills|\n",
      "+---+--------+----------+\n",
      "|  1|   Oveys|      java|\n",
      "|  1|   Oveys|    python|\n",
      "|  2|Mohammad|      Java|\n",
      "|  2|Mohammad|    Python|\n",
      "|  2|Mohammad|    Docker|\n",
      "|  3|     Ala|ObjectiveC|\n",
      "|  3|     Ala|     Swift|\n",
      "|  3|     Ala|   swiftUI|\n",
      "|  3|     Ala|       iOS|\n",
      "+---+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.withColumn('skills', explode(devs.skills)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5732e75d-be79-47f4-b93b-bd371949213c",
   "metadata": {},
   "source": [
    "# split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18414885-fcb2-4e9b-9854-daac06c0754a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------------+\n",
      "| id|    name|              skills|\n",
      "+---+--------+--------------------+\n",
      "|  1|   Oveys|         java,python|\n",
      "|  2|Mohammad|  Java,Python,Docker|\n",
      "|  3|     Ala|ObjectiveC,Swift,...|\n",
      "+---+--------+--------------------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- skills: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Oveys', 'java,python'), (2, 'Mohammad', 'Java,Python,Docker'), (3, 'Ala','ObjectiveC,Swift,swiftUI,iOS')]\n",
    "devs = spark.createDataFrame(data, ['id', 'name', 'skills'])\n",
    "devs.show()\n",
    "devs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e53f775-0413-4dfd-a514-6a8a3e472a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------------+\n",
      "| id|    name|              skills|\n",
      "+---+--------+--------------------+\n",
      "|  1|   Oveys|      [java, python]|\n",
      "|  2|Mohammad|[Java, Python, Do...|\n",
      "|  3|     Ala|[ObjectiveC, Swif...|\n",
      "+---+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.withColumn('skills', split('skills', ',')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79b5ec8-eec7-4097-b294-55e7dc9c2f53",
   "metadata": {},
   "source": [
    "# array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ab71cf00-f29e-4ecf-aac8-4c453a020a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+-------+\n",
      "| id|    name|   skill_1|skill_2|\n",
      "+---+--------+----------+-------+\n",
      "|  1|   Oveys|      java| python|\n",
      "|  2|Mohammad|      Java| Docker|\n",
      "|  3|     Ala|ObjectiveC|  Swift|\n",
      "+---+--------+----------+-------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- skill_1: string (nullable = true)\n",
      " |-- skill_2: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Oveys', 'java','python'), (2, 'Mohammad', 'Java','Docker'), (3, 'Ala','ObjectiveC','Swift')]\n",
    "devs = spark.createDataFrame(data, ['id', 'name', 'skill_1', 'skill_2'])\n",
    "devs.show()\n",
    "devs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b720e738-ff47-4719-9ceb-f4328e6821e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+-------+-------------------+\n",
      "| id|    name|   skill_1|skill_2|             skills|\n",
      "+---+--------+----------+-------+-------------------+\n",
      "|  1|   Oveys|      java| python|     [java, python]|\n",
      "|  2|Mohammad|      Java| Docker|     [Java, Docker]|\n",
      "|  3|     Ala|ObjectiveC|  Swift|[ObjectiveC, Swift]|\n",
      "+---+--------+----------+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.withColumn('skills', array('skill_1', 'skill_2')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e403bd5-9fc9-49ef-8739-169d684cf962",
   "metadata": {},
   "source": [
    "# array_contains()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1cf9b5dc-5bc8-4872-bd05-5838ff1e465a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------------+\n",
      "| id|    name|              skills|\n",
      "+---+--------+--------------------+\n",
      "|  1|   Oveys|      [java, python]|\n",
      "|  2|Mohammad|[Java, Python, Do...|\n",
      "|  3|     Ala|[ObjectiveC, Swif...|\n",
      "+---+--------+--------------------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- skills: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Oveys', ['java', 'python']), (2, 'Mohammad', ['Java', 'Python', 'Docker']), (3, 'Ala',['ObjectiveC', 'Swift', 'swiftUI', 'iOS'])]\n",
    "devs = spark.createDataFrame(data, ['id', 'name', 'skills'])\n",
    "devs.show()\n",
    "devs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "48a43ee3-94d2-4500-ab8d-507a26b51830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------------+---------+\n",
      "| id|    name|              skills|pythonist|\n",
      "+---+--------+--------------------+---------+\n",
      "|  1|   Oveys|      [java, python]|     true|\n",
      "|  2|Mohammad|[java, python, do...|     true|\n",
      "|  3|     Ala|[objectivec, swif...|    false|\n",
      "+---+--------+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def lower_skills(skills):\n",
    "    return [skill.lower() for skill in skills]\n",
    "\n",
    "\n",
    "lower_skills_udf = udf(lower_skills, ArrayType(StringType()))\n",
    "\n",
    "devs.withColumn('skills', lower_skills_udf('skills')).withColumn('pythonist', array_contains('skills', 'python')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a33282-1aae-4c1c-b9d1-e227dbec95ee",
   "metadata": {},
   "source": [
    "# MapType() and explode() on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "19192363-5a4c-4b4c-bb89-fbfb620efdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------------------+\n",
      "|id |name    |properties                |\n",
      "+---+--------+--------------------------+\n",
      "|1  |Oveys   |{age -> 31, height -> 175}|\n",
      "|2  |Mohammad|{age -> 32, height -> 165}|\n",
      "+---+--------+--------------------------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: long (valueContainsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Oveys', {'age':31, 'height':175}), (2, 'Mohammad', {'age':32, 'height':165})]\n",
    "devs = spark.createDataFrame(data, ['id', 'name', 'properties'])\n",
    "devs.show(truncate=False)\n",
    "devs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c5216dc5-db3d-48d9-bd21-dcbd26b114e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------------------+------+-----+\n",
      "|id |name    |properties                |key   |value|\n",
      "+---+--------+--------------------------+------+-----+\n",
      "|1  |Oveys   |{age -> 31, height -> 175}|age   |31   |\n",
      "|1  |Oveys   |{age -> 31, height -> 175}|height|175  |\n",
      "|2  |Mohammad|{age -> 32, height -> 165}|age   |32   |\n",
      "|2  |Mohammad|{age -> 32, height -> 165}|height|165  |\n",
      "+---+--------+--------------------------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.select('id', 'name', 'properties', explode('properties')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "09aa7ca3-b288-4ece-a6c0-09812dc16845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------------------+---------+\n",
      "|id |name    |properties                |values   |\n",
      "+---+--------+--------------------------+---------+\n",
      "|1  |Oveys   |{age -> 31, height -> 175}|[31, 175]|\n",
      "|2  |Mohammad|{age -> 32, height -> 165}|[32, 165]|\n",
      "+---+--------+--------------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.withColumn('values', map_values('properties')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1239e2e-8553-425a-b6ee-c5ae5104a944",
   "metadata": {},
   "source": [
    "# when() otherwise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "afbf5c67-34f8-4976-b368-19ad3aa8629d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+\n",
      "| id|    name|gender|\n",
      "+---+--------+------+\n",
      "|  1|   Oveys|     m|\n",
      "|  2|Mohammad|     m|\n",
      "|  3|     Ala|     f|\n",
      "+---+--------+------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Oveys', 'm'), (2, 'Mohammad', 'm'), (3, 'Ala','f')]\n",
    "devs = spark.createDataFrame(data, ['id', 'name', 'gender'])\n",
    "devs.show()\n",
    "devs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "17b60f6f-ad1b-4422-b926-6381c66b41a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+\n",
      "| id|    name|  sex|\n",
      "+---+--------+-----+\n",
      "|  1|   Oveys| true|\n",
      "|  2|Mohammad| true|\n",
      "|  3|     Ala|false|\n",
      "+---+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.select(\n",
    "    'id',\n",
    "    'name',\n",
    "    when(devs.gender=='m', value=True) \\\n",
    "    .when(devs.gender=='f', value=False) \\\n",
    "    .otherwise(value=None).alias('sex')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f6c2a09b-14c4-4d9d-9bb3-238e91c8fe7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+\n",
      "| id|    name|gender|\n",
      "+---+--------+------+\n",
      "|  1|   Oveys|  true|\n",
      "|  2|Mohammad|  true|\n",
      "|  3|     Ala| false|\n",
      "+---+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.withColumn(\n",
    "    'gender',\n",
    "    when(devs.gender=='m', value=True) \\\n",
    "    .when(devs.gender=='f', value=False) \\\n",
    "    .otherwise(value=None).alias('sex')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc2393d-ac15-476a-b6cd-59398ce7d263",
   "metadata": {},
   "source": [
    "# column's functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1543b6d6-7c49-4f0e-9254-b1b5646653af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+\n",
      "| id|    name|salary|\n",
      "+---+--------+------+\n",
      "|  1|   Oveys|  4000|\n",
      "|  2|Mohammad|  5000|\n",
      "|  3|     Ala|  5500|\n",
      "+---+--------+------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Oveys', 4000), (2, 'Mohammad', 5000), (3, 'Ala',5500)]\n",
    "devs = spark.createDataFrame(data, ['id', 'name', 'salary'])\n",
    "devs.show()\n",
    "devs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1e231e8a-8bec-4993-b5a2-caf204d522ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+\n",
      "|emp_id|    name|salary|\n",
      "+------+--------+------+\n",
      "|     1|   Oveys|  4000|\n",
      "|     2|Mohammad|  5000|\n",
      "|     3|     Ala|  5500|\n",
      "+------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# alias()\n",
    "devs.select(devs.id.alias('emp_id'), devs.name, devs.salary).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "866353d2-782d-47f3-b9d2-16b56063435f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+\n",
      "| id|    name|salary|\n",
      "+---+--------+------+\n",
      "|  1|   Oveys|  4000|\n",
      "|  2|Mohammad|  5000|\n",
      "|  3|     Ala|  5500|\n",
      "+---+--------+------+\n",
      "\n",
      "+---+--------+------+\n",
      "| id|    name|salary|\n",
      "+---+--------+------+\n",
      "|  3|     Ala|  5500|\n",
      "|  2|Mohammad|  5000|\n",
      "|  1|   Oveys|  4000|\n",
      "+---+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# asc() and desc()\n",
    "devs.sort(devs.salary.asc()).show()\n",
    "devs.sort(devs.salary.desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d32fe980-ed3f-46ff-8ffb-73c51181c077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+\n",
      "| id|    name|salary|\n",
      "+---+--------+------+\n",
      "|  1|   Oveys|4000.0|\n",
      "|  2|Mohammad|5000.0|\n",
      "|  3|     Ala|5500.0|\n",
      "+---+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cast()\n",
    "devs.select('id', 'name', devs.salary.cast('float')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0396e777-755b-47b2-8a63-d118f97e3903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+\n",
      "| id|name|salary|\n",
      "+---+----+------+\n",
      "|  3| Ala|  5500|\n",
      "+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# like()\n",
    "devs.filter(devs.name.like('A%')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558c115c-462c-4ece-9a84-e1481b799d51",
   "metadata": {},
   "source": [
    "# filter() and where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fc71be13-6e75-40ea-966a-987e89208014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+\n",
      "| id|    name|salary|\n",
      "+---+--------+------+\n",
      "|  1|   Oveys|  4000|\n",
      "|  2|Mohammad|  5000|\n",
      "|  3|     Ala|  5500|\n",
      "+---+--------+------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Oveys', 4000), (2, 'Mohammad', 5000), (3, 'Ala',5500)]\n",
    "devs = spark.createDataFrame(data, ['id', 'name', 'salary'])\n",
    "devs.show()\n",
    "devs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d04ce94d-25f6-4b3b-bda9-5d279921e3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+\n",
      "| id| name|salary|\n",
      "+---+-----+------+\n",
      "|  1|Oveys|  4000|\n",
      "+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.filter('salary == 4000').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4240a30a-daf7-45dd-bdfd-0a4f17250774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+\n",
      "| id| name|salary|\n",
      "+---+-----+------+\n",
      "|  1|Oveys|  4000|\n",
      "+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.filter(devs.salary == 4000).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3fd33ff1-dcdb-44e9-894d-695c2f0b3bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+\n",
      "| id|name|salary|\n",
      "+---+----+------+\n",
      "|  3| Ala|  5500|\n",
      "+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.where((devs.salary >= 5000) & (devs.name.like('A%'))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1787cd7-2b69-40b1-85db-94a1d0989e04",
   "metadata": {},
   "source": [
    "# distinct() & drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7b969faf-bc78-472a-bf1f-f3aa16ddab2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+------+\n",
      "| id|    name|gender|salary|\n",
      "+---+--------+------+------+\n",
      "|  1|   Oveys|     M|  4000|\n",
      "|  2|Mohammad|     M|  5000|\n",
      "|  2|Mohammad|     M|  5000|\n",
      "|  3|     Ala|     F|  5500|\n",
      "+---+--------+------+------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Oveys','M', 4000), (2, 'Mohammad', 'M', 5000), (2, 'Mohammad', 'M', 5000), (3, 'Ala', 'F', 5500)]\n",
    "devs = spark.createDataFrame(data, ['id', 'name', 'gender', 'salary'])\n",
    "devs.show()\n",
    "devs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "85948554-c35f-4ce8-8952-388da5d0e042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+------+\n",
      "| id|    name|gender|salary|\n",
      "+---+--------+------+------+\n",
      "|  1|   Oveys|     M|  4000|\n",
      "|  2|Mohammad|     M|  5000|\n",
      "|  3|     Ala|     F|  5500|\n",
      "+---+--------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "94833924-3f75-41d0-b7f0-9c1fa9a4fd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+------+\n",
      "| id|    name|gender|salary|\n",
      "+---+--------+------+------+\n",
      "|  1|   Oveys|     M|  4000|\n",
      "|  2|Mohammad|     M|  5000|\n",
      "|  3|     Ala|     F|  5500|\n",
      "+---+--------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drops if there is a duplicate in rows\n",
    "\n",
    "devs.drop_duplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9f057b1a-6d8e-482b-9c10-d73c3e6e748a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+------+\n",
      "| id| name|gender|salary|\n",
      "+---+-----+------+------+\n",
      "|  3|  Ala|     F|  5500|\n",
      "|  1|Oveys|     M|  4000|\n",
      "+---+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drops if there is a duplicate in gender column\n",
    "\n",
    "devs.drop_duplicates(subset=['gender']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597f9b28-e736-4ca7-980c-6521c4df180a",
   "metadata": {},
   "source": [
    "# union()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "14dc7a52-a64d-4489-83e5-8799e22f240d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+------+\n",
      "| id|    name|gender|salary|\n",
      "+---+--------+------+------+\n",
      "|  1|   Oveys|     M|  4000|\n",
      "|  2|Mohammad|     M|  5000|\n",
      "|  2|Mohammad|     M|  5000|\n",
      "|  3|     Ala|     F|  5500|\n",
      "+---+--------+------+------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Oveys','M', 4000), (2, 'Mohammad', 'M', 5000), (2, 'Mohammad', 'M', 5000), (3, 'Ala', 'F', 5500)]\n",
    "devs1 = spark.createDataFrame(data, ['id', 'name', 'gender', 'salary'])\n",
    "devs.show()\n",
    "devs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "30b40f02-d4cc-436e-9c24-6ae387557bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+------+\n",
      "| id|    name|gender|salary|\n",
      "+---+--------+------+------+\n",
      "|  1|     Ali|     M|  4000|\n",
      "|  2|   Jafar|     M|  5000|\n",
      "|  2|Mohammad|     M|  5000|\n",
      "|  2|    Abas|     M|  5000|\n",
      "|  3|    Mona|     F|  5500|\n",
      "+---+--------+------+------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Ali','M', 4000), (2, 'Jafar', 'M', 5000), (2, 'Mohammad', 'M', 5000), (2, 'Abas', 'M', 5000), (3, 'Mona', 'F', 5500)]\n",
    "devs2 = spark.createDataFrame(data, ['id', 'name', 'gender', 'salary'])\n",
    "devs2.show()\n",
    "devs2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f3eaf8e3-701a-498f-9b33-71fb3f683546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 156:============================>                           (8 + 8) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+------+\n",
      "| id|    name|gender|salary|\n",
      "+---+--------+------+------+\n",
      "|  1|   Oveys|     M|  4000|\n",
      "|  2|Mohammad|     M|  5000|\n",
      "|  3|     Ala|     F|  5500|\n",
      "|  1|     Ali|     M|  4000|\n",
      "|  2|   Jafar|     M|  5000|\n",
      "|  2|    Abas|     M|  5000|\n",
      "|  3|    Mona|     F|  5500|\n",
      "+---+--------+------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "devs1.union(devs2).distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33886ae5-288b-46f8-bb92-a9792aa2fef6",
   "metadata": {},
   "source": [
    "# groupBy() and agg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "79141c7c-e01c-4f4e-9bfb-596f7e27bf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+------+\n",
      "| id|    name|gender|salary|\n",
      "+---+--------+------+------+\n",
      "|  1|     Ali|     M|  4000|\n",
      "|  2|   Jafar|     M|  5000|\n",
      "|  7|Mohammad|     M|  5700|\n",
      "|  2|    Abas|     M|  6500|\n",
      "|  3|    Mona|     F|  6200|\n",
      "+---+--------+------+------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    (1, 'Ali','M', 4000),\n",
    "    (2, 'Jafar', 'M', 5000),\n",
    "    (7, 'Mohammad', 'M', 5700),\n",
    "    (2, 'Abas', 'M', 6500),\n",
    "    (3, 'Mona', 'F', 6200)]\n",
    "devs = spark.createDataFrame(data, ['id', 'name', 'gender', 'salary'])\n",
    "devs.show()\n",
    "devs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1f62ba34-3bac-4912-840d-4e8a82c977d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+----------+----------+----------+\n",
      "|gender|emp_count|min_salary|max_salary|avg_salary|\n",
      "+------+---------+----------+----------+----------+\n",
      "|     M|        4|      4000|      6500|    5300.0|\n",
      "|     F|        1|      6200|      6200|    6200.0|\n",
      "+------+---------+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.groupby(devs.gender).agg(\n",
    "    count('*').alias('emp_count'),\n",
    "    min('salary').alias('min_salary'),\n",
    "    max('salary').alias('max_salary'),\n",
    "    avg('salary').alias('avg_salary')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d6ecf3-74a4-481c-b813-740c7a7f6341",
   "metadata": {},
   "source": [
    "# unionByName()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "869354c7-b25a-4089-9aef-62ef00c2013f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+\n",
      "| id|    name|age|salary|\n",
      "+---+--------+---+------+\n",
      "|  1|     Ali| 20|  4000|\n",
      "|  2|   Jafar| 21|  5000|\n",
      "|  2|Mohammad| 23|  5000|\n",
      "|  2|    Abas| 45|  5000|\n",
      "|  3|    Mona| 19|  5500|\n",
      "+---+--------+---+------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+---+--------+------+------+\n",
      "| id|    name|gender|salary|\n",
      "+---+--------+------+------+\n",
      "|  1|     Ali|     M|  4000|\n",
      "|  2|   Jafar|     M|  5000|\n",
      "|  2|Mohammad|     M|  5000|\n",
      "|  2|    Abas|     M|  5000|\n",
      "|  3|    Mona|     F|  5500|\n",
      "+---+--------+------+------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Ali',20, 4000), (2, 'Jafar', 21, 5000), (2, 'Mohammad', 23, 5000), (2, 'Abas', 45, 5000), (3, 'Mona', 19, 5500)]\n",
    "devs1 = spark.createDataFrame(data, ['id', 'name', 'age', 'salary'])\n",
    "devs1.show()\n",
    "devs1.printSchema()\n",
    "\n",
    "data = [(1, 'Ali','M', 4000), (2, 'Jafar', 'M', 5000), (2, 'Mohammad', 'M', 5000), (2, 'Abas', 'M', 5000), (3, 'Mona', 'F', 5500)]\n",
    "devs2 = spark.createDataFrame(data, ['id', 'name', 'gender', 'salary'])\n",
    "devs2.show()\n",
    "devs2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7cda5031-baee-4304-bd00-39b549e853ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----+------+------+\n",
      "| id|    name| age|salary|gender|\n",
      "+---+--------+----+------+------+\n",
      "|  1|     Ali|  20|  4000|  NULL|\n",
      "|  2|   Jafar|  21|  5000|  NULL|\n",
      "|  2|Mohammad|  23|  5000|  NULL|\n",
      "|  2|    Abas|  45|  5000|  NULL|\n",
      "|  3|    Mona|  19|  5500|  NULL|\n",
      "|  1|     Ali|NULL|  4000|     M|\n",
      "|  2|   Jafar|NULL|  5000|     M|\n",
      "|  2|Mohammad|NULL|  5000|     M|\n",
      "|  2|    Abas|NULL|  5000|     M|\n",
      "|  3|    Mona|NULL|  5500|     F|\n",
      "+---+--------+----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs1.unionByName(devs2, allowMissingColumns=True).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30e48fa-1a1d-4bc1-ab97-5cd59ae0efd7",
   "metadata": {},
   "source": [
    "# self join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ed1d2769-c191-44ac-ae30-9f2b20829803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+\n",
      "| id|    name|manager|\n",
      "+---+--------+-------+\n",
      "|  1|     Ali|      0|\n",
      "|  2|   Jafar|      1|\n",
      "|  3|Mohammad|      1|\n",
      "|  4|    Abas|      3|\n",
      "|  5|    Mona|      2|\n",
      "+---+--------+-------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- manager: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Ali',0), (2, 'Jafar', 1), (3, 'Mohammad', 1), (4, 'Abas', 3), (5, 'Mona', 2)]\n",
    "devs = spark.createDataFrame(data, ['id', 'name', 'manager'])\n",
    "devs.show()\n",
    "devs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "19e564ac-ea60-432b-a108-165d5b2e286a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 199:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+----+--------+-------+\n",
      "| id|    name|manager|  id|    name|manager|\n",
      "+---+--------+-------+----+--------+-------+\n",
      "|  1|     Ali|      0|NULL|    NULL|   NULL|\n",
      "|  2|   Jafar|      1|   1|     Ali|      0|\n",
      "|  3|Mohammad|      1|   1|     Ali|      0|\n",
      "|  4|    Abas|      3|   3|Mohammad|      1|\n",
      "|  5|    Mona|      2|   2|   Jafar|      1|\n",
      "+---+--------+-------+----+--------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "devs.alias('emp').join(\n",
    "    devs.alias('mngr'),\n",
    "    col('emp.manager') == col('mngr.id'),\n",
    "    how='left'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86e3431-3ba7-4653-bcb8-fd6afb88807d",
   "metadata": {},
   "source": [
    "# pivot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "77dfc180-f388-43e5-be55-a5c5a37f55d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+----------+\n",
      "| id|    name|gender|department|\n",
      "+---+--------+------+----------+\n",
      "|  1|     Ali|     M|        IT|\n",
      "|  2|   Jafar|     F|        HR|\n",
      "|  3|Mohammad|     M|        HR|\n",
      "|  4|    Abas|     F|        IT|\n",
      "|  5|    Mona|     T|       FIN|\n",
      "+---+--------+------+----------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Ali','M', 'IT'), (2, 'Jafar', 'F', 'HR'), (3, 'Mohammad', 'M', 'HR'), (4, 'Abas', 'F', 'IT'), (5, 'Mona', 'T', 'FIN')]\n",
    "devs = spark.createDataFrame(data, ['id', 'name', 'gender', 'department'])\n",
    "devs.show()\n",
    "devs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f06af409-4f11-4223-ad62-716af4564253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----+----+\n",
      "|department|   F|   M|   T|\n",
      "+----------+----+----+----+\n",
      "|        HR|   1|   1|NULL|\n",
      "|       FIN|NULL|NULL|   1|\n",
      "|        IT|   1|   1|NULL|\n",
      "+----------+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devs.groupBy('department').pivot('gender').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ce8133-b410-41c2-8d75-900ba57837b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can choose which value of the pivots can be showed as columns\n",
    "devs.groupBy('department').pivot('gender', ['M', 'F']).count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cfc711-f9f7-43fd-8418-ab5710d501c1",
   "metadata": {},
   "source": [
    "# udf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f44cee3-6e76-40c8-8512-a50a960ffe3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------------+\n",
      "| id|duration|duration_seconds|\n",
      "+---+--------+----------------+\n",
      "|  1|03:25:45|           12345|\n",
      "|  2|01:10:30|            4230|\n",
      "|  3|05:15:20|           18920|\n",
      "+---+--------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(\"1\", \"03:25:45\"), (\"2\", \"01:10:30\"), (\"3\", \"05:15:20\")]\n",
    "df = spark.createDataFrame(data, [\"id\", \"duration\"])\n",
    "\n",
    "def duration_to_seconds(duration_str):\n",
    "    parts = duration_str.split(':')\n",
    "    hours = int(parts[0])\n",
    "    minutes = int(parts[1])\n",
    "    seconds = int(parts[2])\n",
    "    total_seconds = (hours * 3600) + (minutes * 60) + seconds\n",
    "    return total_seconds\n",
    "\n",
    "df.withColumn(\"duration_seconds\", duration_to_seconds_udf(\"duration\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aea37a0a-a92f-4f40-a6fe-7aca9e6e1e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reason it works without explicitly registering the UDF is because PySpark automatically \n",
    "# converts certain Python functions into UDFs when they are used within DataFrame transformations.\n",
    "# This behavior is called \"automatic UDF registration.\" \n",
    "\n",
    "# Consider example below:\n",
    "# This demonstrates a scenario where you need to explicitly register the function as a UDF because PySpark cannot automatically\n",
    "# handle the transformation due to the use of external Python libraries or complex logic. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38694f57-3b03-4b6b-a416-8e3de2f97c4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object, got 'Column'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m df_with_username \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musername\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mextract_username\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memail\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     15\u001b[0m df_with_username\u001b[38;5;241m.\u001b[39mshow()\n",
      "Cell \u001b[0;32mIn[40], line 7\u001b[0m, in \u001b[0;36mextract_username\u001b[0;34m(email)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_username\u001b[39m(email):\n\u001b[0;32m----> 7\u001b[0m     match \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m^([a-zA-Z0-9_.+-]+)@\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memail\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m match:\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/re/__init__.py:166\u001b[0m, in \u001b[0;36mmatch\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmatch\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    164\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Try to apply the pattern at the start of the string, returning\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    a Match object, or None if no match was found.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object, got 'Column'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "data = [(\"1\", \"john.doe@example.com\"), (\"2\", \"jane.smith@example.com\"), (\"3\", \"mike.jones@example.com\")]\n",
    "df = spark.createDataFrame(data, [\"id\", \"email\"])\n",
    "\n",
    "def extract_username(email):\n",
    "    match = re.match(r'^([a-zA-Z0-9_.+-]+)@', email)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df_with_username = df.withColumn(\"username\", extract_username(df.email))\n",
    "\n",
    "df_with_username.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45df5b27-8084-4429-8ec1-72df7b5ad335",
   "metadata": {},
   "source": [
    "# using udf for sql temporary tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78086171-135f-4252-98d9-04155360c401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+-----+\n",
      "| id|    name|salary|bonus|\n",
      "+---+--------+------+-----+\n",
      "|  1|     Ali|  4000|    0|\n",
      "|  2|   Jafar|  2800|  400|\n",
      "|  3|Mohammad|  3000|  500|\n",
      "|  4|    Abas|     0|    0|\n",
      "|  5|    Mona|  2200|  300|\n",
      "+---+--------+------+-----+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      " |-- bonus: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Ali',4000, 0), (2, 'Jafar', 2800, 400), (3, 'Mohammad', 3000, 500), (4, 'Abas', 0, 0), (5, 'Mona', 2200, 300)]\n",
    "devs = spark.createDataFrame(data, ['id', 'name', 'salary', 'bonus'])\n",
    "devs.show()\n",
    "devs.printSchema()\n",
    "devs.createOrReplaceTempView('devs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "53bcaa6a-8960-4bb0-b2ef-ad0da5e90014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_salary(salary: int, bonus: int) -> int:\n",
    "\n",
    "    return salary + bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6305f95f-080b-4a81-b6aa-b4810bb40c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/30 20:58:57 WARN SimpleFunctionRegistry: The function udf_sum_salary_sql replaced a previously registered function.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.sum_salary(salary: int, bonus: int) -> int>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.udf.register(name='udf_sum_salary_sql', f=sum_salary, returnType=IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f9b5da6-0202-40e5-9b51-097440a21541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+\n",
      "| id|    name|sum_salary|\n",
      "+---+--------+----------+\n",
      "|  1|     Ali|      4000|\n",
      "|  2|   Jafar|      3200|\n",
      "|  3|Mohammad|      3500|\n",
      "|  4|    Abas|         0|\n",
      "|  5|    Mona|      2500|\n",
      "+---+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select id, name,udf_sum_salary_sql(salary, bonus) as sum_salary from devs\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a734af79-3703-4a6c-8bac-0f84f1e1c05a",
   "metadata": {},
   "source": [
    "# window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54495ea5-284f-486d-96ff-7eac1ecba8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+-----+---------+\n",
      "|      date|         t_id|price|shop_name|\n",
      "+----------+-------------+-----+---------+\n",
      "|2023-01-03|       123123|  227|    edeka|\n",
      "|2023-01-03|       123124|   24|     rewe|\n",
      "|2023-01-03|          234|   24|     rewe|\n",
      "|2023-01-04|       423423|   45|    edeka|\n",
      "|2023-01-05|       424332|   65| eurogida|\n",
      "|2023-01-06|        53454|   85|     aldi|\n",
      "|2023-01-07|      1534543|   43|     rewe|\n",
      "|2023-01-08|      3534434|   32|     rewe|\n",
      "|2023-01-08|     56556332|   22|     rewe|\n",
      "|2023-01-11| 768679823749|   31|     rewe|\n",
      "|2023-01-12|8652438736478|   54|     rewe|\n",
      "|2023-01-13|  93487264823|   41|     rewe|\n",
      "|2023-01-09|       122567|   76|     aldi|\n",
      "+----------+-------------+-----+---------+\n",
      "\n",
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- t_id: string (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      " |-- shop_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transaction_data = [\n",
    "    ('2023-01-03', '123123', 227, 'edeka'),\n",
    "    ('2023-01-03', '123124', 24, 'rewe'),\n",
    "    ('2023-01-03', '234', 24, 'rewe'),\n",
    "    ('2023-01-04', '423423', 45, 'edeka'),\n",
    "    ('2023-01-05', '424332', 65, 'eurogida'),\n",
    "    ('2023-01-06', '53454', 85, 'aldi'),\n",
    "    ('2023-01-07', '1534543', 43, 'rewe'),\n",
    "    ('2023-01-08', '3534434', 32, 'rewe'),\n",
    "    ('2023-01-08', '56556332', 22, 'rewe'),\n",
    "    ('2023-01-11', '768679823749', 31, 'rewe'),\n",
    "    ('2023-01-12', '8652438736478', 54, 'rewe'),\n",
    "    ('2023-01-13', '93487264823', 41, 'rewe'),\n",
    "    ('2023-01-09', '122567', 76, 'aldi'),\n",
    "]\n",
    "\n",
    "schema = StructType() \\\n",
    "    .add('date', StringType()) \\\n",
    "    .add('t_id', StringType()) \\\n",
    "    .add('price', IntegerType()) \\\n",
    "    .add('shop_name', StringType())\n",
    "\n",
    "transactions = spark.createDataFrame(\n",
    "    data=transaction_data,\n",
    "    schema=schema\n",
    ")\n",
    "\n",
    "transactions.show()\n",
    "transactions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c5b0bc1b-0b80-4e64-a27d-079ba73a6b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = Window.orderBy('date', 'price').partitionBy('shop_name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f4a28949-9111-4662-bae2-ea58c461bc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-----+-----+----+----+-----+-------------------+----+----+----+-------+\n",
      "|      date|shop_name|price|first| nth|rank|dense|       percent_rank|lead| lag|last|row_num|\n",
      "+----------+---------+-----+-----+----+----+-----+-------------------+----+----+----+-------+\n",
      "|2023-01-06|     aldi|   85|   85|NULL|   1|    1|                0.0|  76|NULL|  85|      1|\n",
      "|2023-01-09|     aldi|   76|   85|NULL|   2|    2|                1.0|NULL|  85|  76|      2|\n",
      "|2023-01-03|    edeka|  227|  227|NULL|   1|    1|                0.0|  45|NULL| 227|      1|\n",
      "|2023-01-04|    edeka|   45|  227|NULL|   2|    2|                1.0|NULL| 227|  45|      2|\n",
      "|2023-01-05| eurogida|   65|   65|NULL|   1|    1|                0.0|NULL|NULL|  65|      1|\n",
      "|2023-01-03|     rewe|   24|   24|NULL|   1|    1|                0.0|  24|NULL|  24|      1|\n",
      "|2023-01-03|     rewe|   24|   24|NULL|   1|    1|                0.0|  43|  24|  24|      2|\n",
      "|2023-01-07|     rewe|   43|   24|NULL|   3|    2| 0.2857142857142857|  22|  24|  43|      3|\n",
      "|2023-01-08|     rewe|   22|   24|NULL|   4|    3|0.42857142857142855|  32|  43|  22|      4|\n",
      "|2023-01-08|     rewe|   32|   24|  32|   5|    4| 0.5714285714285714|  31|  22|  32|      5|\n",
      "|2023-01-11|     rewe|   31|   24|  32|   6|    5| 0.7142857142857143|  54|  32|  31|      6|\n",
      "|2023-01-12|     rewe|   54|   24|  32|   7|    6| 0.8571428571428571|  41|  31|  54|      7|\n",
      "|2023-01-13|     rewe|   41|   24|  32|   8|    7|                1.0|NULL|  54|  41|      8|\n",
      "+----------+---------+-----+-----+----+----+-----+-------------------+----+----+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactions.select('date', 'shop_name', 'price') \\\n",
    "    .withColumn('first', first('price').over(window)) \\\n",
    "    .withColumn('nth', nth_value('price', 5).over(window)) \\\n",
    "    .withColumn('rank', rank().over(window)) \\\n",
    "    .withColumn('dense', dense_rank().over(window)) \\\n",
    "    .withColumn('percent_rank', percent_rank().over(window)) \\\n",
    "    .withColumn('lead', lead('price', 1).over(window)) \\\n",
    "    .withColumn('lag', lag('price', 1).over(window)) \\\n",
    "    .withColumn('last', last('price').over(window)) \\\n",
    "    .withColumn('row_num', row_number().over(window)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad6a952-3783-48ae-aa58-74b8b62b4353",
   "metadata": {},
   "source": [
    "# apply map() on DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96f95609-7743-48c9-8d50-0f3347acc70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|first_name| last_name|\n",
      "+----------+----------+\n",
      "|     Oveys|Safarnejad|\n",
      "|       Ala|   Nourani|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [('Oveys', 'Safarnejad'), ('Ala', 'Nourani')]\n",
    "schema = StructType().add('first_name', StringType()).add('last_name', StringType())\n",
    "\n",
    "persons = spark.createDataFrame(data, schema)\n",
    "persons.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9705154-0aa2-405e-bd39-d6c8bd103e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|       full_name|\n",
      "+----------------+\n",
      "|Oveys Safarnejad|\n",
      "|     Ala Nourani|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dataframes don't support map() on their rows\n",
    "# You have to convert it to a RDD and then apply map() on them, finally you can reconvert it to dataframe.\n",
    "persons_maped_rdd = persons.rdd.map(lambda x: (x[0] + ' ' + x[1],))\n",
    "persons_maped_rdd.toDF(schema=['full_name']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74653fdc-472b-49fc-bc09-ec0f072e829e",
   "metadata": {},
   "source": [
    "# partion data on write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c7a7f5f-9fa2-4e37-8561-13f9d4fe809e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+----------+\n",
      "| id|    name|gender|department|\n",
      "+---+--------+------+----------+\n",
      "|  1|     Ali|     M|        IT|\n",
      "|  2|   Jafar|     F|        HR|\n",
      "|  3|Mohammad|     M|      NULL|\n",
      "|  4|    Abas|     F|        IT|\n",
      "|  5|    Mona|     T|       FIN|\n",
      "+---+--------+------+----------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Ali','M', 'IT'), (2, 'Jafar', 'F', 'HR'), (3, 'Mohammad', 'M', None), (4, 'Abas', 'F', 'IT'), (5, 'Mona', 'T', 'FIN')]\n",
    "devs = spark.createDataFrame(data, ['id', 'name', 'gender', 'department'])\n",
    "devs.show()\n",
    "devs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "caaff26d-8bce-4a91-a94f-188827bd562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "devs.write.parquet('./devs/parquests', partitionBy='department', mode='overwrite')\n",
    "# This partionBy parameter will devide data into different sections based on department column value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc89022d-e1fd-4652-8e98-b902602b1877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+----------+\n",
      "| id|    name|gender|department|\n",
      "+---+--------+------+----------+\n",
      "|  3|Mohammad|     M|      NULL|\n",
      "|  2|   Jafar|     F|        HR|\n",
      "|  4|    Abas|     F|        IT|\n",
      "|  5|    Mona|     T|       FIN|\n",
      "|  1|     Ali|     M|        IT|\n",
      "+---+--------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.parquet('./devs/parquests').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac304646-decd-41bf-85ae-29c43d06c6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+\n",
      "| id| name|gender|\n",
      "+---+-----+------+\n",
      "|  2|Jafar|     F|\n",
      "+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.parquet('./devs/parquests/department=HR').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df22ff69-5a3c-4270-a445-233a1a278893",
   "metadata": {},
   "source": [
    "# from_json()\n",
    "##### it will accept a column of type string and convert it to MapType or StructType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "aefaefe4-3cb7-4219-9576-1208d45a5ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- props: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------------------------+\n",
      "|name |props                             |\n",
      "+-----+----------------------------------+\n",
      "|Oveys|{\"age\": 31, \"hair_color\": \"black\"}|\n",
      "|Ala  |{\"age\": 32, \"hair_color\": \"pink\"} |\n",
      "+-----+----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    ('Oveys', '{\"age\": 31, \"hair_color\": \"black\"}'), \n",
    "    ('Ala', '{\"age\": 32, \"hair_color\": \"pink\"}'), \n",
    "]\n",
    "\n",
    "persons = spark.createDataFrame(data, schema=['name', 'props'])\n",
    "\n",
    "persons.printSchema()\n",
    "persons.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e599b147-af62-4df5-9ff2-dbee3ac289da",
   "metadata": {},
   "source": [
    "### The question is to convert values in the map type column into different columns ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "98731e04-9c3b-4eac-b661-010fadd9d845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+---+\n",
      "| name|hair_color|age|\n",
      "+-----+----------+---+\n",
      "|Oveys|     black| 31|\n",
      "|  Ala|      pink| 32|\n",
      "+-----+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "keys = persons.select(\n",
    "    explode(\n",
    "        map_keys(\n",
    "            from_json(\n",
    "                'props',\n",
    "                schema=MapType(StringType(),StringType())\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "exprs = [from_json(col('props'),schema=MapType(StringType(),StringType())).getItem(k).alias(k) for k in keys]\n",
    "persons.select('name', *exprs).show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a7fe0b7e-155c-41f1-9320-5430b3aabc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+\n",
      "| name|age|hair_color|\n",
      "+-----+---+----------+\n",
      "|Oveys| 31|     black|\n",
      "|  Ala| 32|      pink|\n",
      "+-----+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this way is more optimized since it is not calling collect() which may cause performance issue on large datasets.\n",
    "\n",
    "json_schema = spark.read.json(persons.rdd.map(lambda r: r.props)).schema\n",
    "persons = persons.withColumn(\"_c\", from_json(\"props\", json_schema))\n",
    "persons.select(\"name\", \"_c.*\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e0dc3f-f18f-47f5-9b4b-d3ad1fdf9959",
   "metadata": {},
   "source": [
    "# to_json()\n",
    "###### It will convert a column from MapType or StructType to json string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30dcb62e-1fe1-4640-8726-7ce871c50881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- props: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: long (valueContainsNull = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------------+\n",
      "|name |props                          |\n",
      "+-----+-------------------------------+\n",
      "|Oveys|{age -> 31, hair_color -> NULL}|\n",
      "|Ala  |{age -> 32, hair_color -> NULL}|\n",
      "+-----+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    ('Oveys', {\"age\": 31, \"hair_color\": \"black\"}), \n",
    "    ('Ala', {\"age\": 32, \"hair_color\": \"pink\"}), \n",
    "]\n",
    "\n",
    "persons = spark.createDataFrame(data, schema=['name', 'props'])\n",
    "\n",
    "persons.printSchema()\n",
    "persons.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb352b43-842e-44cf-8f1e-fea8e52413bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------------+----------------------------+\n",
      "|name |props                          |json_props                  |\n",
      "+-----+-------------------------------+----------------------------+\n",
      "|Oveys|{age -> 31, hair_color -> NULL}|{\"age\":31,\"hair_color\":null}|\n",
      "|Ala  |{age -> 32, hair_color -> NULL}|{\"age\":32,\"hair_color\":null}|\n",
      "+-----+-------------------------------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons.withColumn('json_props', to_json('props')).show(truncate=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3378f6-fcc3-4739-bd4f-7ee7760b0982",
   "metadata": {},
   "source": [
    "# json_tuple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc5829c0-fddc-40b8-9cb1-9eafc26b9125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- props: string (nullable = true)\n",
      "\n",
      "+-----+-----------------------------------------------------+\n",
      "|name |props                                                |\n",
      "+-----+-----------------------------------------------------+\n",
      "|Oveys|{\"hair_color\":\"black\", \"eye_color\":\"black\", \"age\":31}|\n",
      "|Ala  |{\"hair_color\":\"brown\", \"eye_color\":\"brown\", \"age\":32}|\n",
      "+-----+-----------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    ('Oveys', '{\"hair_color\":\"black\", \"eye_color\":\"black\", \"age\":31}'),\n",
    "    ('Ala', '{\"hair_color\":\"brown\", \"eye_color\":\"brown\", \"age\":32}')\n",
    "]\n",
    "schema = StructType(\n",
    "    [StructField('name', StringType()), StructField('props', StringType())]\n",
    ")\n",
    "\n",
    "persons = spark.createDataFrame(data, schema)\n",
    "\n",
    "persons.printSchema()\n",
    "persons.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30294840-daa7-4e50-ad12-2b3b46deed46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+---+\n",
      "| name|hair_color|age|\n",
      "+-----+----------+---+\n",
      "|Oveys|     black| 31|\n",
      "|  Ala|     brown| 32|\n",
      "+-----+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons.select('name', json_tuple('props', 'hair_color', 'age').alias('hair_color', 'age')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab634c69-21dc-4cb8-9d02-a4d9cdc201a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3c670000-523f-4105-b49c-7df8678369b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# titanic_1.fillna(value='GG', subset='cabin').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef47d93-c3f1-4aed-84d6-84be3e73e252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
