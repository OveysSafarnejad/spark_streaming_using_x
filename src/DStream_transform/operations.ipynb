{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e11fcdcb-f35b-4af2-885f-84bd2f197ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/audioworkstation/Documents/WORKSPACE/LEARNING/spark_streaming_using_x/spark-3.5.0-bin-hadoop3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import random\n",
    "import pathlib\n",
    "import findspark\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark import SparkConf\n",
    "\n",
    "from apache_log_parser import ApacheAccessLog\n",
    "\n",
    "\n",
    "os.environ['SPARK_HOME'] = '/Users/audioworkstation/Documents/WORKSPACE/LEARNING/spark_streaming_using_x/spark-3.5.0-bin-hadoop3'\n",
    "os.environ['PYSPARK_DEIVER_PYTHON'] = 'jupyter'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS'] = 'lab'\n",
    "os.environ['PYSPARK_PYTHON'] = 'python'\n",
    "\n",
    "\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc85267c-4603-4c88-8ec9-1fef060ce68d",
   "metadata": {},
   "source": [
    "# apache log parser example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d4edce2-d186-489d-a3b6-c0130129dcb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/15 14:00:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "/Users/audioworkstation/Documents/WORKSPACE/LEARNING/spark_streaming_using_x/.venv/lib/python3.10/site-packages/pyspark/streaming/context.py:72: FutureWarning: DStream is deprecated as of Spark 3.4.0. Migrate to Structured Streaming.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "random.seed(15)\n",
    "conf = (SparkConf().setMaster('local[2]').setAppName('TextUpdater').set('spark.executer.memory', '2g'))\n",
    "sc = SparkContext(conf=conf)\n",
    "ssc = StreamingContext(sparkContext=sc, batchDuration=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3df91859-1695-455a-8d31-f68de350a152",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.checkpoint('MyCheckPoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b09acae-0936-45f3-98e6-c230e3554620",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr = pathlib.Path().resolve()\n",
    "logs_directory = os.path.join(curr / 'logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12ad5558-406d-4934-bd74-bda241d7cf44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/audioworkstation/Documents/WORKSPACE/LEARNING/spark_streaming_using_x/Transform Operations/logs'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab0fa912-a442-4b70-85ec-cb34b9b25ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data = ssc.textFileStream(logs_directory)\n",
    "access_log_dstream = log_data.map(\n",
    "    ApacheAccessLog.parse_from_log_line\n",
    ").filter(\n",
    "    lambda parsed_line: parsed_line is not None\n",
    ")\n",
    "\n",
    "access_log_dstream.pprint(num=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d468d2bb-7f93-4736-ab69-d95ff2e960f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_ip_values(rdd):\n",
    "    return rdd.map(lambda parsed_line: (parsed_line.ip, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c910e01-4a3e-4143-bbfc-205f3d1886aa",
   "metadata": {},
   "source": [
    "### functions that are supplied to transform get called in every batch interval\n",
    "### means that we can create operations for rdds that vary by time\n",
    "\n",
    "# BUT WHAT IS THE DIFFERENCE BETWEEN THESE TWO LINES BELOW?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18595070-805a-4874-8530-a68e8cfa6f2b",
   "metadata": {},
   "source": [
    "### This (transform) is useful when you need to perform operations that involve the entire batch, such as aggregations, sorting, or any operation that requires context across multiple elements.\n",
    "\n",
    "### map produces a one-to-one transformation, meaning each input element produces exactly one output element.\n",
    "### transform allows you to produce a different number of output elements than the number of input elements. This can be useful in various scenarios.\n",
    "\n",
    "### here's an example:\n",
    "```\n",
    "def complex_transform(rdd):\n",
    "    # Perform a complex transformation on the entire batch\n",
    "    # This function can involve filtering, sorting, or any custom logic\n",
    "    return rdd.filter(lambda x: x > 5).map(lambda x: (x, x * 2))\n",
    "\n",
    "transformed_dstream = original_dstream.transform(complex_transform)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "187dc727-6520-408f-82ff-ef5431df8d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_access_log_dstream = access_log_dstream.transform(map_ip_values)  # It's like saying: \"For the entire set of log entries, do this specific operation.\"\n",
    "# transformed_access_log_dstream = access_log_dstream.map(lambda parsed_line: (parsed_line.ip, 1)) # It's like saying: \"For each log entry, give me a tuple with the IP and a 1.\"\n",
    "transformed_access_log_dstream.pprint(num=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5149e9e2-2043-4585-b8f0-e4a0cea15185",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2023-11-15 14:03:30\n",
      "-------------------------------------------\n",
      "64.242.88.10 - - [07/Mar/2004:21:14:32 -0800] \"GET /twiki/bin/rdiff/TWiki/FileAttribute HTTP/1.1\" 200 \n",
      "h24-70-56-49.ca.shawcable.net - - [07/Mar/2004:21:16:17 -0800] \"GET /twiki/view/Main/WebHome HTTP/1.1\" 404 \n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2023-11-15 14:03:30\n",
      "-------------------------------------------\n",
      "('64.242.88.10', 1)\n",
      "('h24-70-56-49.ca.shawcable.net', 1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2023-11-15 14:04:00\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2023-11-15 14:04:00\n",
      "-------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae6ba3b-9713-41d0-ae48-4f126994213b",
   "metadata": {},
   "source": [
    "##### after starting ssc you can move your logs into the log folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91a42ef-7476-4c68-a95f-b927d30aeace",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.stop(stopSparkContext=True, stopGraceFully=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
