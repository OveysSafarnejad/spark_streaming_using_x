{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ce8fc7-302f-472c-9282-578b5d0adb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import findspark\n",
    "from operator import add\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import SQLContext, Row, SparkSession\n",
    "from pyspark.sql.functions import regexp_replace, col, trim, lower, desc\n",
    "\n",
    "prj_home = pathlib.Path().resolve().parent.parent\n",
    "spark_home = os.path.join(prj_home / 'spark-3.5.0-bin-hadoop3')\n",
    "findspark.init(spark_home)\n",
    "\n",
    "sc = SparkContext(master='', appName='PySparkSqlContext') # machine that spark runs and the number of worker threads\n",
    "ssc = StreamingContext(sparkContext=sc, batchDuration=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168d88ce-582f-4120-83b8-cdb2490e002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spark_session_interface(sparkConf):\n",
    "    if 'sparkSessionSingletonInstance' not in globals():\n",
    "        globals()['sparkSessionSingletonInstance'] = SparkSession.builder.config(conf=sparkConf).getOrCreate()\n",
    "    return globals()['sparkSessionSingletonInstance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca591bd3-6c7a-4a32-8ca3-1eb5a4a27339",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = '127.0.0.1'\n",
    "port = '5555'\n",
    "\n",
    "lines = ssc.socketTextStream(host, int(port))\n",
    "seprated = lines.flatMap(lambda l: l.split(' '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d103453-521a-4229-a141-a88cd00a43a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(time, rdd):\n",
    "    print(f\"-.-.-.-.-.-.-.-.-.- %s -.-.-.-..-.-.-..-.-.-\" % str(time))\n",
    "    if not rdd.isEmpty():\n",
    "        session = get_spark_session_interface(rdd.context.getConf())\n",
    "        rows_data = rdd.map(lambda word: Row(word_col=word))\n",
    "        words_df = session.createDataFrame(rows_data)\n",
    "        words_df.createOrReplaceTempView('words')\n",
    "\n",
    "        word_count_df = session.sql('select word_col, count(*) from words group by word_col')\n",
    "        word_count_df.show()\n",
    "    \n",
    "    else:\n",
    "        print(\"No stream received!\")\n",
    "\n",
    "seprated.foreachRDD(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225b9fb4-43bb-4fc2-977b-f07305de2184",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b64c6be-01e3-4996-9d5c-72da8007196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssc.stop(stopGraceFully=True, stopSparkContext=True)\n",
    "ssc.awaitTerminationOrTimeout(timeout=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
